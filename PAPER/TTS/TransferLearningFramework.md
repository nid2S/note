# Paper
- [Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus](https://arxiv.org/pdf/2203.15447.pdf)
- 이름 그대로 트랜스퍼 러닝을 위한 라이브러리를 소개한 논문. supported by Samsung Research, Samsung Electronics.
## Model
- 사용모델 : 약간의 수정을 거친 VITS. 전사되지 않은 거대 음성 corpus에서 사전훈련한 뒤, 조금의 text-labeled 데이터셋으로 파인튜닝함.
- 사전훈련 : 유사음소(pseudo phoneme)라고 명명된 새로음 음성토큰(phonetic token)이 음소 대용으로 사전훈련에 사용됨. 

## 유사음소(pseudo phoneme)
- 유사음소 : 음성 정보를 포함하는 토큰. 사전훈련에서 음소를 대체해 사용됨. 효과적인 사전훈련을 위해 음소와 비슷한 특성을 가져야 하며, 
  지도학습을 쓰지 않기 위해 음성만 있는 corpus에서 획득되어야 함(이를 위해 논문에선 self-supervised방식으로 사전훈련된 wav2vec2.0의 은닉표현을 이용함).
  wav2vec2.0의 은닉표현 상의 k-평균 클러스터링이 음소 토큰을 각 speech frame에 할당하는데 잘 작동한다고 함. 
- 추출 : 먼저 전체 unlabeld corpus에 대한 블록15의 은닉표현에서 K개의 클러스터 식별을 위해 k-mean클러스터링을 수행한 뒤, 블록15의 은닉표현을{h_1 ... h_T}로 나타내고 각 클러스터 인덱스 i{1 ... K(128)}가 각각의 h로부터 얻어짐.
  이 후 같고 연속된 인덱스는 실제 음소의 특성을 반영하기 위해 병합됨. 이렇게 병합된 인덱스들을 유사음소라고 참조하며 이를 사전훈련을 위해 사용함.

## TTS TransferLearning Framework
- 구조 : 조건부 변화적인 오토인코더(CVAE)구조의 VITS 아키텍쳐 상에서 빌드. VITS는 후방 인코더, 전방 인코더, 디코더, 지속 예측기로 이루어져 있음. 
  추가로, 적대적 훈련이 높은 충실도의 사운드를 생성하는데 도움이 됨.
- posterior encoder(후방 인코더): 주어진 선형 스펙트로그램의 후방 은닉변수 분포를 추출함.
- prior encoder(전방 인코더): 정규화 흐름과 text인코더로 구성되어있고, 조건부 이전 분포, 주어진 텍스트, 정렬(MAS(monotonic alignment search)알고리즘에 의해 계산)을 일치시킴. 
- decoder : sample로부터 output audio를 생성함.
- duration predictor(지속 예측기) : 각 음소의 지속을 정렬을 사용해 학습함.
- Speaker Embedding : zero-shot multi-speaker TTS에서는 스피커 임베딩의 추출을 위한 참조 인코더를 추가함. 
  스피커 임베딩은 정규화 흐름의 affine coupling layers에서 조건화 되며, text-speaker의존적 사전 분포를 생성함.

- 사전훈련 : 두가지 차이점이 있는 바닐라 VITS 훈련방법을 이용함. 두가지 차이점은 유사음소와 유사 텍스트 인코더가 음소와 텍스트 인코더 대신 사용됨.
- pseudo text encoder(유사 텍스트 인코더): 2개의 1D Conv + ReLU 레이어로 구성되어 있음. 따라서, 훈련객체는 주어진 유사음소 speech의 최대 조건부확률로 수정되며 
  따라서 사전 matching을 위한 KLD(Kullback-Leibler divergence)loss도 바뀌게 됨.

- 파인튜닝 : 파인튜닝의 목표는 사전훈련된 모델을 음소 시퀀스에 적응시키는 것. 파인튜닝동안 유사음소와 유사텍스트인코더는 음소와 텍스트 인코더로 교체되며 KLD loss또한 일반적으로 돌아오게 됨.
  효율적인 훈련을 위해 모델을 frozen, fine-tunned, scratch 세 단계로 나눔.
- frozen : 디코더와 후방 인코더는 사전훈련동안 동결(frozen)됨. 둘의 역할은 고품질의 raw audio 재구성 하는것이기에, 해당 모듈들이 거대 corpus에서 충분히 훈련되었으며 적은 데이터셋에서 파인튜닝 될 필요가 없다고 추정하기에 동결함.
  동결된 디코더는 몇가지의 이점을 유발하는데, 동결된 디코더에 순전파를 할 필요가 없어 많은 메모리소비와 고해상도 오디오 생산을 위한 연산을 아낄 수 있음. 게다가 speech output이 없으므로 훈련절차를 더 복잡하게 만드는 VITS의 적대적 훈련을 생략할 수 있음.
  ZS-TTS의 경우에선 reference encoder또한 동결되는데, 이는 적은 speaker로 파인튜닝 시키는 것이 본적없는 화자에 대한 일반적인 성능을 저하시킬 수 있다고 추정하기 때문임.
  한편 정규화 흐름은 유사음소 종속적 선행(pseudo phoneme dependent prior)을 음소 종속적 선행으로 조정하기 위해 파인튜닝됨. 이것은 음소와 유사음소간 불일치를 완화시킬 수 있음.
- scratch : 텍스트 인코더와 지속 예측기는 scratch로부터 학습됨. 더나은 일반화를 위해 지속 예측기에는 조건speaker임베딩을 수행하지 않음. 
- fine-tuned : 오직 파인튜닝만 되는 부분은 정규화 흐름 뿐이며, 오직 KLD loss와 지속예측기의 loss만이 파인튜닝을 위해 사용됨.

- 프레임워크 디자인 : 기존 전이학습 방법과 제안된 프레임워크간 주의할만한 차이점이 있는데, 전이학습에서 도메인은 D={X(특성space), P(x)(확률분포)}로 정의되며, task는 T={Y(레이블space), F(x)(객관적예측함수)}로 정의됨.
  소스도메인과 소스task는 타겟도메인 속 타겟task의 타겟함수의 학습에 도움이 될 수 있음. 그런데 여기선 소스도메인(유사음소인덱스)과 타겟도메인(음소인덱스)가 어떤 일반특성space도 공유하지 않는 대신 각 label sapce가 높게 관련되어있음.
- 문제 : 위의 이유로, 순전파 TTS모델은 제안된 함수에 적합하지 않음. 도메인이 바뀌면 텍스트 인코더는 특성공간이 불일치하므로 랜덤으로 초기화되어야 하고, 디코더는 학습되지 않은 특성을 받게 됨.
  이는 사전훈련으로 부터 얻은 디코더의 지식을 활용하기 어렵게 만들고, 파인튜닝동안 치명적인 망각을 유발함. 
- 해결 : 이를 해결하기 위해 정규화 흐름의 가역성을 이용. 정규화 흐름은 훈련과 추론 절차를 위한 반대방향을 가지고 있음. 훈련절차에선 후방 인코더의 출력은 정규화 흐름의 은닉변수로 바뀌고, 
  이는 도메인shift문제를 타겟shift문제로 바꿈. 유사음소는 많은 음성정보를 가지고, 텍스트 인코더는 빠르게 잘 정의된 은닉상태와 텍스트와 유사음소간의 차이에 적응한 정규화 흐름을 배울 수 있음.

