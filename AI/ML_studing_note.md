#AI
- 인공지능 : 지능적인 인간의 행동을 모방하는 기계의 능력.
- 심볼릭 AI(symbolic AI) : 프로그래머들이 명시적인 규칙을 충분히 많이 만들면 일반지능(인간수준 인공지능)을 만들 수 있다는 접근 방법. 전문가 시스템과도 연관되어 있음.
- 머신러닝(Machine Learning) : 인공지능의 한 분야, 알고리즘을 이용해 데이터를 분석하고, 그를 통해 학습하며, 그 내용을 기반으로 판단이나 예측을 함. 지도학습과 비지도 학습이 포함되어 있음.
- 딥러닝(Deep Learning) : 인공 신경망에서 발전. 몇 층의 인공 신경망을 이용. 데이터 군집화나 추상화를 시도함(여러 비선형 변환기법의 조합을 통함).
- 훈련용, 검증용, 테스트로 데이터셋을 나눠, 훈련데이터로 모델 학습 > 검증데이터로 하이퍼파라미터 조절 > 테스트데이터로 모델 성능 확인 의 과정을 거침.
  검증데이터와 테스트데이터를 나눌만큼 데이터가 충분하지 않다면 k-fold교차검증 등의 방법을 사용하기도 함. 
- AI학습 흐름 : Y = f(Wx * X + b)(순전파, 예측값 생성) -> 손실 측정(손실함수 이용) -> 가중치, 편향 조정(역전파, optimizer 사용)  
- 가설(모델)적용 > 손실 측정 > 역전파를 통한 파라미터 갱신. 위 과정을 epoch(데이터셋 전부사용)만큼 반복. 
  미니배치를 사용한다면 Iteration(TotalData/BatchSize)개의 미니배치를 학습해야 하나의 epoch가 끝남.
  
- 머신러닝은 최적화와 일반화를 잘 조절해야 함. 100%에 가까운 모델을 만들고, 그 후 일반화를 진행. 데이터 사이즈가 같을때 정확도를 높이려면 층을 추가하고, 크기를 키우고, epoch 를 높이면 됨. 

- 모델을 학습할 때에는 데이터 형태확인(data Engineering 으로 데이터를 다듬거나 새 특성을 찾아내기도 함) > 전처리(normalization, one-hot-encoding) > 모델 생성 및 학습으로 이뤄짐.
- ML시 필요한 폴더의 종류는 rawdata, prep_data, model, lastest_acc(최신 모델의 정확도를 저장해 이후 모델과 비교), train(학습프로그램 패키징), stage(학습시 staging)등이 있을 수 있음. 

##용어
***
- 기호주의 AI : 규칙기반 AI
- 연결주의 AI : 신경망기반 AI | 머신러닝(베이지안,HMM,SVM등 | 신경망기반 AI - 딥러닝)
- 통계적 AI : 머신러닝(베이지안,HMM(히든 마르코프 모델),SVM등 | 신경망기반 AI - 딥러닝)

- 일반화 : 모델이 처음보는 데이터를 정확하게 예측할 수 있다면, 그것을 훈련세트에서 테스트 세트로 일반화 되었다고 함.
- 과대적합 : 모델이 훈련세트에 너무 가깝게 밎게되어 일반화 되기 어려울때 일어나는 것. 이를 막기위해 모든 특성이 출력에 주는 영향을 최소한으로 만들게(규제)한다.
- 과소적합 : 모델이 너무 간단해 데이터의 면면과 다양성을 잡아내지도 못하고, 훈련세트에도 맞지 않는것. 
  테스트 세트의 성능이 좋았더라도 테스트 세트와 점수가 비슷하다면 과소적합일 가능성이 있어, 모델의 성능을 더욱 올릴 수 있다.
- 역전파 : 순전파(평범하게 가설을 이용해 예측값 도출)연산 > 오차(손실, 비용)계산 > 기울기 계산(손실 미분) 의 과정을 거쳐 나온 값을 통해 파라미터를 갱신하는 과정. 
  출력층에서부터 이전층으로 이동하며(역전파 1단계 > 2단계)해당 단계의 파라미터들을 갱신. 
  손실을 구한 후 [d손실/d파라미터\]를 계산(체인 룰 이용, 계산이 가능하게 변경), 이를 optimizer를 이용해(식에 적용해)계산.

##정확도 계산(metrics)
***
- Accuracy(정확도) : 모든 예측이 실제로 맞은 비율. 
- Precision(정밀도) : True 라고 예측한 것중 실제로 True 인 비율. 양성 예측도(PPV)라고도 함. 거짓 양성을 줄여야 할 떄 사용. 
- Recall(재현율) : 모든 true 중 true 로 예측한 것의 비율. 민감도, 적중률, 진짜 양성 비율(TPR)이라고도 함. 모든 양성을 식별, 즉 거짓 음성을 줄여야 할 때 사용.
- F1-score : 정밀도와 재현율의 조화평균(역수의 평균의 역수, 곱/합)*2. 정밀도와 재현율이 서로 상충하고 둘 중 하나만으로는 전체 그림을 볼 수 없기 때문에 사용한다. 
  F1-measure 라고도 한다. 기본 임계값에 대한 점수이다.
- RMSE : 평균제곱근오차(Root MSE). √(MSE). 회귀모델에 사용.
- MAE : 평균절대오차(Mean Absolute error). 손실의 절댓값의 평균. 회귀모델에 사용. 

- ROUGE : 요약(summarization)에서의 성능평가를 위한 지표. 생성한 서머리와 레퍼런스를 
  precision(서머리의 단어중 정답에 등장한 단어 비율)과 recall(서머리의 단어중 실제로 등장한 단어 비율)을 이용해 스코어링(f1 Measure).
- ROUGE-1 : 레퍼런스와 모델 서머리간 겹치는 unigram 수를 봄.
- ROUGE-2 : 레퍼런스와 모델 서머리간 겹치는 bigram 수를 봄.
- ROUGE-S : window size가 주어졌을때, 사이즈 내에 위치하는 단어쌍을 묶어 중복되는 정도를 봄.
- ROUGE-L : LCS(Longest common subsequence)를 사용해 최장길이로 매칭되는 문자열 측정.

- macro 평균 : 클래스 크기에 상관 없이 모든 클래스를 같은 비중으로 다룬다.
- weighted 평균 : 클래스별 샘플 수로 가중치를 둬 f1 점수의 평균을 계산.
- micro 평균 : 모든 클래스의 거짓 양성(FP), 거짓 음성(FN), 진짜 양성(TP)의 수를 세어 정밀도, 재현율, f1점수를 이걸로 계산한다.

#### 벡터간 거리(유사도)측정법
- 유클리디안 거리(Euclidean Distance) : 피타고라스의 정리를 이용, 두 벡터간 직선 거리를 측정. sqrt(pow(sum((qi-pi)), 2)).
- 맨해튼 거리(Manhattan Distance) : 정사각형으로 나뉜 곳(격자)에서 두 점사이의 거리를 측정. 택시거리(Taxicab distance)라고도 함. sum(abs(pi-qi)).
- 민코프스키 거리(Minkowski Distance) : 위의 두가지 거리를 일반화 한 것. pow(sum(pow(abs(xi-yi), p)), 1/p).
  p=1이면 맨해튼거리와 동일(pow전부 소멸)하며, L1규제(norm)라고도 한다. p=2면 유클리드 거리와 동일(제곱 후 제곱근)하며, L2규제라고도 한다.
  p=∞면 체비셰프거리와 동일하며, Lmax norm이라고도 함.
- 체비셰프 거리(Chebyshev Distance) : 가로,세로,대각선으로 이동할 수 있는 물체의 거리. 맨해튼 거리에서 대각선으로도 이동할 수 있다고 보면 됨(대각선도 1). max(abs(xi-yi)).
- 코사인 거리(Cosine Similarity) : 두 벡터가 이루는 각도(각의 코사인값)를 통해 유사도를 측정. 벡터의 크기를 고려하고 싶지 않을때 사용. AB/abs(A)abs(B) = sum(aibi)/√sum(ai²)√sum(bi²)

#### 모델 평가
- 교차검증 : 데이터를 여러번 반복해서 나누고 여려 모델을 학습한다. 일반화 성능을 재기 위한 안정적이고 뛰어난 통계적 평가 방법. 
  각 샘플이 한번씩 들어가 점수를 높이려면 모든 샘플에 대해 잘 일반화 되어야 하며, 모델이 훈련 데이터에 얼마나 민감한지 파악 가능하다는 정보를 얻을 수 있고, 
  데이터를 효과적으로 사용할 수 있다는 장점을 갖지만, 연산 비용이 늘어난다는 단점이 있다.
- 교차 검증은 물론 필요하지만, 이것이나 테스트 데이터셋을 모델이나 모델의 매개변수 선택에 사용해서는 안된다.
- K-fold Test : 전체 데이터를 다양한 방법으로 쪼개 훈련,테스트,검증의 과정을 여러번(K번) 반복하며 테스트가 편향되어 있지 않고 설명력을 가지게 하려 시행.
- k-겹 교차검증 : 보통 회귀일 경우 사용. 데이터를 k 개로 폴드(비슷한 크기의 부분집합으로 나눔)한다. 보통 5나 10을 주로 사용하고, 
  총 k 개의 모델을 만들어 각 모델은 자기 순서의 폴드를 테스트 세트로, 다른 모델은 트레인 세트로 사용해 훈련을 진행한다.  
- 계층별 k-겹 교차검증 : 보통 분류일 경우 사용. 데이터가 계층별로 나눠져 있을 때 위의 방법에는 문제가 있어 대신 사용하는 방법. 
  분류기의 일반화 성능 측정 시 더 안정적이라 이것을 사용하는게 좋다.
- LOOCV(leave-one-out cross-validation) : 폴드 하나에 샘플 하나만 들어있는 k-겹 교차검증. 데이터 셋이 크면 시간이 걸리지만 작은 데이터 셋에선 종종 더 좋은 효과를 낸다.
- 임의 분할 교차 검증 : train_size 만큼 훈련세트를 만들고, 그것과 중복되지 않은 포인트로 test_size 만큼 테스트 세트를 만든다. 반복 횟수를 독립적으로 조절해야 할 때, 
  전체 데이터의 일부만 사용하고 싶을 때(훈련과 실험의 합을 전체와 다르게 해 가능), 대규모 데이터 셋으로 작업할 떄(부분 샘플링 방식) 유용하다.
- 그룹별 교차 검증 : 훈련세트와 테스트 세트를 만들 때 분리되지 않아야 할 그룹을 지정하여 같이 넘길 수 있는 교차 검증 방법. 이를 위해 model_selection.GroupKFold 메서드를 제공함.
- 반복 교차 검증 : 데이터셋이 그리 크지 않은 경우 안정된 점수를 얻기 위해 교차검증을 반복해 여러번 수행하는 것. 
- 중첩 교차 검증 : 바깥쪽 루프에서 데이터를 훈련과 테스트로 나누고, 각 훈련세트에 대해 그리드 서치를 실행한 뒤, 
  밖에서 테스트 세트에 대해 각각 측정해 특정 데이터 셋에서 모델이 얼마나 잘 일반화 되는지 평가하는데 유용하게 사용할 수 있다. 예측 모델의 제작에는 거의 사용하지 않는다.

- 분류 평가 지표 : 거짓 양성과 거짓 음성이 있는데, 보통 둘의 중요도가 비슷한 경우는 거의 없어 모델 평가시 이를 주의해야 한다.
- 오차 행렬 : 이진 분류 평가를 나타낼 때 가장 많이 사용하는 방법이지만 다중 분류애서도 사용할 수 있다. 클래스*클래스의 크기로, 
  \[\[클1 예측 수, 클2 예측 수](다 합치면 클1 요소 개수), \[클1 예측 수, 클2 예측 수]\(클2)] 식으로 나와, 대각 행렬(i\*i)이 클래스별 정답의 개수가 된다. 
- 불확실성 고려 : 대부분의 분류기는 decision_function 이나 predict_proba 라는 메서드를 제공하는데, 예측은 이것의 출력의 임계값을 검증(0, 0.5(0~1로 고정) 가 기본)하는 것으로, 
  이를 조정하면 더 넓은 범위의 데이터 포인트를 그 클래스로 넣을 수 있다. 이렇게 분류기의 필요 조건을 지정하는것을 운영 포인트 지정이라고 하며, 
  임계값 조정은 따로 데이터셋을 만들어(혹은 교차검증) 수행해야 한다.
- 정밀도-재현율 곡선 : 새 모델을 만들 때 운영포인트가 명확하지 않아 문제를 더 잘 이해하기 위해 모든 임계값을 조사해 보거나 정밀도, 재현율의 장단점을 한번에 살펴보기위해 사용. 
- 평균 정밀도 : 전체 곡선에 담긴 정보를 요약하는 방법중의 하나로, 곡선의 아랫부분 면적이다. 모든 임계값에 대한 평균을 뜻한다.
- ROC 곡선 : 여러 임계값에서 분류기의 특성을 분석하는데 사용. 정밀도와 재현율 대신 TPR(진짜 양성 비율, 재현율)에 대한 FPR(거짓 양성 비율)을 나타낸다. 
  곡선 아래 면적(AUC)으로 요약해 사용할 수 있고, 이는 불균형한 데이터 셋에서 정확도보다 훨씬 좋은 지표이다.
- 회귀도 이진 분류와 비슷하게(과대예측 대비 과소 예측을 분석한다던가) 할 수 있지만 대부분 score 에서 사용하는 R^2 만으로 충분하다.

- 오프라인 평가 : 사전에 수집한 테스트 세트를 기초로 알고리즘이 만든 예측을 평가하는 방법. 알고리즘을 평가하는 첫 단계.
- 온라인 테스트 : 전체 시스템에 알고리즘이 적용된 이후 평가하는 것. 
- A/B 테스트 : 알고리즘을 변경하면 생기는 사용자의 행동을 크게 바꾸거나 예상치 못한 결과를 얻는 등의 돌발상황 방지를 위한 일종의 블라인드 테스트. 
  사용자 일부가 자신도 모르게 각 알고리즘을 사용하게 되고, 그 결과로 두 알고리즘 중 하나를 선택하는 방법. 

## 전처리
- 데이터의 스케일에 매우 민감한 알고리즘들은 그에 맞게 데이터의 특성값을 조정해야 하며, 특성마다 스케일을 조정해 데이터를 변경함.
- 데이터 벡터화 : 입력 데이터를 텐서로 변경하는 것.
- 원 핫 인코딩 : 해당 정보는 1, 니머지는 0으로 표기하는 방법. 영양없는 정보는 0을 대입해 행렬 곱셈 연산등에서 빠른 연산속도를 얻는다.  
  
- 정규화 : 각 입력데이터의 범위나 크기가 다를경우 네트워크 학습이 어려워, 특정 범위 이내로 만드는 것. 일반적으로 평균이 0이고 표준 편차가 1이 되는 0과 1 사이의 값으로 변환. 
- 정규 분포 : 모든 데이터를 (데이터-평균)/표준편차 로 정규화 해 평균이 0이고 표준 편차가 1이 되는 0과 1 사이의 값으로 변환한 분포.
- 균등 분포 : 모든 데이터를 같은 확률(비율)로 모아 0~1 사이에 분포시킴.
 
- StandardScaler : 각 특성의 평균을 0, 표준편차 1로 변경해 모든 특성이 값은 크기를 가지게 함. 최솟값과 최댓값의 크기를 제한하지는 않음. (데이터-평균)/표준편차.  
- RobustScaler : 특성들이 같은 스케일을 갖게 하지만 평균과 분산 대신 중간값과 사분위 값을 사용해 이상치(전체 데이터와 아주 동떨어진 데이터)에 영향을 받지 않게 함.
- MinMaxScaler : 모든 특성이 정확하게 0과 1 사이에 위치하도록 데이터 변경. 
- QuantileTransformer : 여러개의 분위(Quantile)를 이용해 데이터 균등 분포. 이상치에 민감하지 않으며 젠체 데이터를 0과 1 사이에 위치시킴.`` 
- Normalizer : 특성 벡터의 유클리디안 길이가 1이 되도록 데이터를 조정. 각 데이터가 다른 비율로 스케일 조정. 길이는 상관 없이 데이터의 방향(각도)만 중요할 떄 많이 사용됨.

- 주성분 분석 (PCA): 특성들이 통계적으로 상관관계가 없도록 데이터셋을 회전시키는 기술. 분산이 가장 큰 방향(주된 분산의 방향, 주성분)을 찾음. 
  주성분의 일부만 남기는 차원 축소 용도나 특성 추출에도 사용.
- 비음수 행렬 분해 (NMF) : 유용한 특성을 뽑아내기 위한 또다른 비지도 알고리즘. 데이터의 극단 또는 일부분에 상응되는 중첩가능 성분을 찾음. 
  PCA 와 달리 음수가 아닌 성분과 계수값을 찾음. 음수가 아닌 특성을 가진 데이터에만 적용 가능. 패턴을 추출해 섞여있는 
  데이터에서 원본 성분을 구분할 수 있음(소리, 유전자 표현, 텍스트 데이터등에 적합함). PCA 에 비해 해석하기 쉬움.
- 매니 폴드 학습 : 위의 둘보다 월씬 복잡한 매핑을 민들어 더 나은 시각화를 제공함. 탐색적 데이터 분석에는 유용하나 학습한 데이터가 아니면 분해할 수 없기에 지도학습용으로는 사용하지 않음. 
- t-SNE : 매니폴드 학습의 알고리즘. 훈련 데이터는 다른 데이터로 바꿀 수 있지만, 다른 새로운 데이터는 적용할 수 없음. 데이터 사이를 가장 잘 보존하는 2차원 표현을 찾음. 
  각 데이터 포인트를 무작위로 2차원에 배열한 후 원래와 가까운건 더 가깝게, 먼건 더 멀게 만듦.
- 군집(clustering) : 데이터셋을 클러스터로 나눔. 데이터 마이닝 기법의 일환으로, 하드클러스터링(데이터 포인트 하나는 하나의 클러스터에 포함, 보편적)과 
  소프트 클러스터링(포인트 하나가 여러 클러스터 포함가능)이 있다. 비즈니스 목적에 따라 지도활동이 추가되는 경우가 있다. 
  모든 클러스터의 반경이 똑같다고 가정하기에 비교적 간단한 형태를 구분가능. 
- k-평균 군집 : 가장 간단하고 널리 사용되는 군집 알고리즘. 무작위로 클러스터의 중심을 할당한 후, 데이터 포인트를 가장 가까운 클러스터 중심에 할당하고, 
  클러스터의 데이터 포인트의 평균으로 중심을 재지정하는 과정을 중심에 변화가 없을때까지 거친다. 클러스터의 번호에는 아무 의미 없으며, 
  그저 같은 클러스터의 데이터들은 서로 닮았다는 것을 알려줄 뿐임. 활용 범위가 제한적이며, 찾으려는 클러스터의 개수를 지정해야 한다는 문제점이 있다.
- 병합 군집 : 각 포인트를 하나의 클러스터로 지정하고, 종료 조건을 만족할 때 까지 가장 비슷한 두 클러스터를 합침. 계층적 군집을 만듦.
- DBSCAN : 클러스터 개수 지정 필요 x, 복잡형상 구분 가능, 클래스 없는 포인트 구분 가능. 
  특성 공간에서 데이터가 많아 붐비는 지역의 포인트(밀집지역)를 찾고, 그걸로 클러스터를 생성. 밀집지역 의 중심인 포인트를 핵심 샘플이라고 한다.
- 군집 알고리즘 비교, 평가 방법 : 최적(1)일때와 무작위(0)일때 사이의 값을 제공하는, accuracy 가 아닌 adjusted_rand_score(ARI)나 
  normalized_mutual_info_score(NMI), silhouette_score(데이터의 밀집도) 등의 군집용 측정 도구(metrics.cluster 에서 확인 가능) 가 있지만, 
  결국 가장 정확한 방법은 시각화를 해 직접 확인해 보는 것이다.

- 특성 공학 : 특정 앱에 가장 적합한 표현을 찾는 것.
- 구간 분할 : 한 특성을 여러 특성으로 나누는 연속형 데이터에 아주 강력한 선형 모델을 만드는 방법. 연속형 특성을 확장하는 방법. 
  기본적으로 상숫값을 학습하지만, 구간분할된 원래 특성을 다시 추가하면 기울기를 추가할 수 있다.
- 상호작용, 다항식 추가 : 특성을 풍부하게 나타내는 또 하나의 방법. 통계적 모델링과 일반적 머신러닝 앱에서도 많이 적용함.  
  각 구간에서 다른 기울기를 지니게 하기 위해 상호작용 특성(구간 특성\*원본특성)을 추가하거나 x**10까지 고차항(다항식)을 추가하는 등의 방법이다.    

- 일변량 통계 : 특성 자동 선택. 개개의 특성과 타깃 사이에 중요한 통계적 관계가 있는지 파악. 분류에서는 분산분석 이라고 함. 
  각 특성이 독립적으로 평가되어 다른 특성과 깊게 연관된 특성은 선택되지 않음. 특성이 많아서 모델 제작이 어렵거나 확실히 도움이 되지 않는다고 생각할 때 사용하면 좋다. 
- 모델 기반 선택 : 지도학습 모델을 사용해 특성의 중요도를 평가. 한 번에 모든 특성 고려.
- 반복적 선택 : 특성의 수가 각기 다른 모델을 생성. 특성이 하나도 없다가 종료조건까지 추가하거나, 특성을 전부 가지고 있다가 종료조건까지 하나씩 제거(재귀적 특성 제거, RFE)하거나 한다. 

###### 매개변수 튜닝
- 그리드 서치 : 매개변수를 튜닝(중요한 매개변수의 일반화 성능을 최대로 높여주는 값을 찾음)해 일반화 성능을 개선. 매개변수들을 대상으로 가능함 모든 조합을 시도.
  for 문으로도 간단히 사용가능하며, 사용시 훈련, 매개변수 검증, 모델 테스트 셋으로 데이터 셋을 나눠야 한다. 
- 비대칭 매개변수 그리드 탐색 : 모든 매개변수의 조합에 대해 그리드서치를 수행 하지 않아야 하는 경우(특정 매개변수에 특정 값이 들어가면 특정 매개변수를 사용하지 않는다 던가),
  param_grid 에 딕셔너리의 리스트 형태로 넣어주면 사용할 수 있다. 파이프 라인 객체를 그리드 서치에 사용하려면 파라미터들을{'이름__매개변수':[수들의 리스트]} 식으로 작성해야 한다. 

- Pipeline : 분류기 등의 지도학습 모델과 전처리 단계를 연결할 때 사용하는 사이킷런의 파이썬클래스. 여러 처리 단계를 사이킷런 추정기 형태로 묶어준다. 
  스케일 조정시 조정을 위해 테스트 부분 전체를 학습하는데, 이때 교차검증을 위한 테스트 속 검증 폴드마저 한번 학습하기 때문에 테스트 데이터에서 유출되는 정보가 생기며, 
  이를 해결하기 위해 교차검증의 분할이 전처리보다 먼저 이뤄지게 하기 위해 전처리 과정과 모델을 묶어 분할 > 전처리 > 모델 사용 의 과정이 되게 한다.
- 파이프 라인은 보통 그리드 서치를 위해 사용되는데, 그저 연결만 하는 것을 넘어 파이프 라인을 구성하는 단계(어떤 스케일러를 사용할지 등)도 그리드 서치로 탐색할 수 있지만,
  이러면 탐색 범위가 더 넓어지니 주의가 필요하다. 딕셔너리의 리스트 형태로 만들어 사용가능. 
- 대규모 그리드 서치를 할 때에는 종종 동일한 단계가 여러번 수행되는데, 이때는 파이프 라인의 memory 매개 변수를 사용하여 계산 결과를 캐싱할 수 있지만
  캐시는 디스크에 저장되어 관리되기에 디스크에 읽고 쓰기 위한 직렬화가 필요하고, 최악의 경우 사용되는 cpu 만큼의 작업 프로세스가 캐시되기 전 
  동시에 동일한 계산을 중복으로 수행할 수 있다는 문제점이 있다.
- dask-ml 라이브러리의 GridSearchCV 를 쓰면 모든 단점을 피할 수 있다.

###### 텍스트 데이터
- 수치형, 범주형과 구분되는 또 다른 데이터 유형. 총 4종류 중 하나로 표현되며 알고리즘 적용 전에 전처리가 필요하다.
- 범주형 텍스트 데이터 : 고정된 목록으로 구성. 메뉴 중 하나를 고르는 설문조사 등에서 볼 수 있는 데이터.
- 범주에 의미를 연결가능한 문자열 : 말그대로. 텍스트 필드로 응답을 받는 설문조사 등에서 볼 수 있는 데이터.
- 구조화 된 문자열 : 주소나 장소, 이름, 날짜, 전화번호등 일정한 구조를 가지는 문자열.
- 텍스트 데이터 : 자유로운 형태의 절과 문장으로 구성된 데이터. 

- 어간 추출 : 일일히 어미를 찾아 제거하는 규칙기반 방식. 더 좋은 일반화를 위해 각 단어를 단어의 어간으로 표현해 같은 어간을 가진 단어를 구분하기(합치기) 위해 사용한다.
- 표제어 추출 : 알려진 단어의 형태사전을 사용하고 문장에서 단어의 역할을 고려하는 처리 방식. 둘다 단어의 일반 형태를 추출하는 정규화의 한 형태로 볼 수 있음. 
  어간 추출보다 훨씬 복잡한 처리를 거치지만 토큰 정규화시 더 좋은 성능을 냄.

- BOW(bag of wards) : 가장 간단하지만 효과적이고 널리 쓰이는 방법. 토큰화 > 어휘사전 구축(모든 어휘를 모으고 알파벳 순으로 번호를 매김) > 
  인코딩(단어가 얼마나 나오는지 셈, 희소행렬로 만들기 등) 의 과정을 거친다.
- tf-idf : 얼마나 의미있는 특성인지 계산해서 스케일을 조정하는 방식. 다른 문서보다 특정 문서에서 자주 나타나는 단어에 높은 가중치를 주는 방법.
- n-그램 : BOW 를 사용할 때 문맥까지 같이 고려하는 방법으로 옆에 있는 토큰 몇개를 함께 고려한다. 두개는 바이그램, 세개는 트라이 그램이며(혼자있는 토큰은 유니그램) 
  일반적으로 연속된 토큰을 n-그램이라고 한다.  

- 토픽 모델링 : 비지도 학습으로 문서를 하나 또는 그 이상의 토픽에 할당하는 작업.
- LDA(잠재 디리클레 할당, Latent Dirichlet Allocation) : 토픽 모델링시 사용하는 특정한 성분 분해 방법. 자주 자타나는 단어의 그룹을 찾음. 
  SVD(행렬분해)를 자연어처리, 토픽모델링에 적용. 

##ML
***
- Discriminative model : 흔히 사용하는 머신러닝의 학습 방법. 적은 데이터로도 작동하고 연산량이 상대적으로 적으나 오버피팅의 위험이 있음.
  두 클래스가 얼마다 다른가에 초점. decision boundery를 그려 속하는 쪽을 선정.  
- Generative model : 머신러닝 모델의 크게 두가지로 분류되는 학습 방법 중 하나. 데이터가 많을수록 학습이 잘 됨. 언어 모델의 학습 방법. 각 클래스의 분포도를 사용.  
  x와 y(각 클래스)가 동시에 일어날 확률을 구해(joint probability) 더 높은 클래스로 선정. 데이터만 많으면 과적합의 걱정이 적고 더 정확한 분류가 가능하나 데이터가 많아야하고, 연산량이 많음.

### 지도학습
- 입출력 데이터기반 예측.
- 분류 : 나올 수 있는 응답이 개별적(국가나 언어등 둘 사이에 무언가가 없음). 레이블이 이산형 범주. 출력층의 노드수는 레이블 개수와 동일해야 함.
> - 이진 분류 : 범주 두개(y/n). 대부분의 선형 분류가 속함. 대표적으로 로지스틱 회귀. y=f(Wx+b)의 식을 사용.
> - 다중분류 : 범주 새개 이상. 이진분류를 다중분류로 확장하기 위해서는 일 대 다 라는 방법을 사용함.
> - 일 대 다 : 각 클래스를 다른 모든것과 비교하도록 훈련시킴.

- 회귀 : 나올 수 있는 응답이 연속적. 레이블이 연속형인 숫자.
> - 선형회귀 : 데이터의 추세가 선형인 회귀. y=Wx+b(독립변수 하나)의 식을 사용.
```python 선형 회귀 구현
learning_late = 0.01  # 학습룰 0.01로 설정
epoch = 300  # 학습 횟수는 300번으로 설정
W = tf.Variable(1.0)
b = tf.Variable(1.0) # 가중치, 편향 선언
X = [1,2,3,4,5]
y = [12,23,34,45,56]  # 학습 데이터 설정

def hypo(x):  # 가설(가중치와 편향)을 적용해 값을 반환하는 함수
  return W*x + b
def mse(y_pred, t):  # 평균 오차 제곱 손실함수
  return tf.reduce_mean(tf.square(y_pred - y) 차이값을 제곱한 뒤 평균을 구함
optimizer = tf.optimizer.SGD(learning_late)  # 옵티마이저는 경사 하강법, 학습률은 0.01로

for i in range(epoch):
  y_pred = hypo(X)  # 식 수행
  cost = mse(y_pred, y)  # 결과의 비용(본래와의 평균 제곱 오차)
  gradients = tf.GradientTape().gradients(zip(gradients, [W, b])  # 비용에 대한 파라미터 미분값 계산
  optimizer.apply_gradients(zip(gradients, [W, b]))  # 파라미터 업데이트
 ```

#### 모델
##### KNN(nearest neighbor)
- 최근접 이웃 : 작은 데이터셋일 경우 기본 모델로 좋고, 설명도 편함.
  
##### linear
- 선형 모델 : 대용량, 고차원 데이터셋에 사용 가능.
- 리지 선형 회귀 모델 : 선형 회귀 모델에 가중치의 합이 최소가 되도록 L2 규제를 추가한다.
- 라소 선형 회귀 모델 : 리지와 비슷하나  L1 규제를 걸어 어떤 값이 0이 될 수 있게 한다.
  
- 로지스틱 회귀 : 이진회귀를 위한 대표적인 선형 알고리즘. 분류모델에 주로 쓰임. 

##### autoregressive
- 자기회귀 모델 : 변수의 과거값의 선형 조합을 이용해 특정 변수를 예측. 변수의 과거값을 이용한 다중회귀모델과 동잏함.

##### naive bayes
- 나이브 베이즈 : 분류 전용. 선형 모델에 비해 훨씬 빠름. 대용량, 고차원 데이터셋에 사용가능. 베이즈의 정리를 이용.
- 베이즈의 정리 : 조건부 확률을 계산하는 방법 중 하나. P(A)가 A가 일어날 확률, P(B|A)가 A가 일어난 후 B가 일어날 확률 이라고 했을 때 P(A|B)=(P(B|A)P(A))/P(B) 의 공식을 따른다. 
- 베이즈의 정리 이용 : P(레이블 | 입력 텍스트)(입력 텍스트가 그 레이블일 확률) = P(w1(본문의 단어) | 레이블) × P(w2 | 레이블) × P(w3 | 레이블) × P(레이블). 
  오직 단어의 빈도수만을 고려.

- Naive Bayes(NB) - 선형 분류기보다 훈련 속도가 빠르지만 일반화 성능이 조금 뒤짐.
- GaussianNB - 연속적인 어떤 데이터에도 적용가능. 각 특성의 표준편차와 평균을 저장. 고차원의 데이터셋에 사용.
- BernoulliNB - 이진데이터에 적용. 각 클래스의 특성 중 0이 아닌것을 셈. 커질수록 모델이 단순해지는 alpha 가 있음.
- MultinomialNB - 카운트(count) 데이터에 적용. 클래스별 특성의 평균을 계산. alpha.

##### dicision tree
- 결정 트리 : 매우 빠르며 데이터 스케일 조정이 필요 없음. 시각화와 설명하기 좋음.
- 랜덤 포레스트 : 결정트리 하나보다 좋은 성능을 냄. 안정적이고 강력하며 데이터 스케일 조정이 필요 없지만 고차원 희소 데이터와는 안 맞음.
- 그래디언트 부스팅 결정 트리 : 랜덤 포레스트보다 성능이 좋고 예측리 빠르며 메모리를 덜 사용하지만 힉습이 느리고 매개변수 튜닝이 많이 필요함.
- 결정트리 :  예/아니오를 반복하며 학습. 각 분열된 영역(리프)가 하나의 타깃값을 가질때 까지 반복. 이때의 리프노드를 순수노드라고 함.  
- 과대적합을 막기 위해 가지치기(사전 - 최대 깊이, 개수 제한, 최소 포인트 개수 제한 | 사후 - 데이터가 적은 노드 삭제)를 해줘야 함.
 
##### ensenble
- 앙상블 : 여러 모델을 연결해 더 강력한 모델을 만드는 기법. 랜덤 포레스트와 그래디언트 부스팅등이 있다.
- 랜덤 포레스트 : 조금씩 다른 여러 결정 트리의 묶음. 다른 방향으로 과대적합된 트리들을 평균냄. 여러개의 데이터중에서 무작위로 만들어낸 데이터의 부트스트랩 샘플을 생성한다. 
  모든 츠리에 대한 예측을 만든 후, 그 예측을 평균하거나(회귀) 예측한 확률을 평균내어(분류) 예측값을 나타낸다. 트리가 많을수록 랜덤값에 영향을 덜 받는다. 
  많은 트리는 메모리와 긴 훈련시간을 부른다. 차원이 높고 희소한 데이터에는 잘 작동하지 않는다.
- 그래디언트 부스팅 회귀트리 : 약한 학습기 사용. 이전 트리의 오차를 보완하는 방법으로 순차적으로 만듦. 무작위성이 없고, 적은 메모리와 예측도 빠름. 
  랜덤포레스트 보다 매개변수의 영향을 더 많이 받는다. 커질수록 보정을 많이해 복잡한 모델을 만드는 러닝 레이트 매개변수를 가지고 있다. 랜덤 포레스트보다 조금 더 불안정하다. 
- 배깅 : Bootstrap aggregating 의 줄임.  랜덤 샘플링으로 훈련세트를 각기 달리 훈련시킨 뒤 확률값을 평균하거나 빈도가 가장 높은 예측결과 예측값이 된다.
- 엑스트라 트리 : 후보 특성을 무작위 분할 후 최적의 분할을 민듦. 랜덤 포래스트와 다른 방식으로 모델에 무작위성을 주입. 
- 에이다 부스트 : 약한 학습기 사용. adaptive Boosting. 이전 모델이 잘못 분류한 샘플의 가중치를 높임. 각 모델은 성능에 따라 가중치가 부여. 깊이 1의 트리 사용.
   
##### SVM
- 서포트 벡터 머신 : 비슷한 의미의 특성으로 이뤄진 중간규모 데이터 셋에 잘 맞음. 데이터 스케일 조정이 필요하고 매개변수 튜닝이 맣이 필요함.
- 커널 기법 : 선형 모델(분류기)을 새로운 특성을 많이 만들지 않고도 학습시키기 위한 수학적 기교.
- 커널 서포트 벡터 머신 : 커널 기법을 이용한 SVM. 데이터의 특성이 몇 개 안 되도 복잡한 결정 결계를 만들 수 있으나 샘플이 많으면 잘 맞지 않는다.

##### NN
- 신경망 : 대용량 데이터 세트에서 복잡한 모델을 만들 수 있음. 매개변수 선택과 대이터 스케일에 민감. 큰 모델은 학습이 오래 걸림.
- tf 에서 딥러닝 모델 생성 : 데이터 생성 > 전처리 > 모델 레이어 제작 > compile > fit > predict 의 순서로 이뤄진다.

##### 머신러닝 모델 구현 (keras)
###### Sequential
- 시퀀셜 : 단순하게 층을 쌓는 방식으로 쉽고 간단하게 사용가능. 다수의 입출력을 가진 모델이나 층간 연결, 덧셈등의 연산을 하는 모델을 구현하기에 부적합. 
- 구현 방법 : model = Sequential() 후 model.add(layer)로 층을 추가해 만들 수 있음. 시퀀셜 모델 제작시 초기 매개변수로 최대 세개까지 층을 추가할 수 있다. 
###### function API
- function : 각 층이 함수형태로 되어 있음. 시퀀셜로는 구현하기 어려운 복잡한 모델 구현 가능. layer()(이전레이어) 로 제작됨.
- 선형 회귀 : output = Dense(1, activation='linear')(inputs) > Model(input, output) 으로 제작 후, compile(optimizer=SGD(), loss='mse', metrics=['mse'])로 컴파일
- 로지스틱 회귀 분류(이진분류): output = Dense(1, activation='sigmoid')(inputs) > Model(inputs, output).  
- 다중입력을 받는 모델 : input 을 여러개 만들고, 각 입력에 대해 모델을 만든 뒤, concatenate([m1.output, m2.output])로 둘의 출력을 연결, 
  Dense(2, activation="relu")(result)식으로 연결값을 입력으로 받는 층 추가 > 출력층 추가 > Model(inputs=[x.input, y.input], outputs=z)로 최종 제작의 과정을 거쳐 만들 수 있음.    
###### Subclassing API
- Subclassing : 모델이 클래스 형태로 되어 있음. 객체지향에 익숙해야 해 코드 사용이 가장 까다로움. pytorch와 비슷한 방식.
- 사용 이유 : 간단한 모델을 구현하기에 적합하고, 함수형 API 로 구현이 불가능한 모델(재귀 네트워크, 트리 RNN 등. 함수형 API 가 모델을 DAG 로 취금하기 때문)도 구현가능한 경우가 있음.
- 구조 : 
```python 
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

class MyModel(Model):  # 모델을 상속하는 모델클래스 생성  
    def __init__(self):
        super(MyModel, self).__init__()             # 자기자신을 인자로 넘기며 __init__()
        self.dense1 = Dense(64, activation='relu')  # 사용할 층 정의
        self.dense2 = Dense(10, activation='softmax')

    def call(self, x):
        x = self.dense1(x)  # 정의한 층을 이용해(input은 입력됨)모델 생성, 최종 층 반환
        x = self.dense2(x)
        return x
    
```

### DeepLearning
***
#### 인공신경망 
- 학습이 오래 걸리고 데이터 전처리에 주의해야 한다는 문제점이 있음. 같은 의미를 가진 동질의 데이터에서 잘 작동함.
- 뉴런에서 연산 > 결과가 활성화 함수를 지남 > 손실예측 > 가중치 업데이트 > epoch만큼 반복 의 과정을 거침.

- 입력에 대한 순전파(FF)연산 > 그를 통해 나온 예측과 실제의 오차를 손실함수로 계산 > 그 손실을 미분해 기울기를 구함 > 그로 역전파(BP)를 수행 의 과정을 거침.
- 입력이 여러개인 식의 경우 \[Y = x1\*w1 + x2*w2 + b] 식으로 구성되는데, 이는 \[X={x1,x2}, W={{w1},{w2}} B={{b1}} | Y = XW + B]식으로 행렬간의 연산으로 바꿀 수 있음.

- 퍼셉트론 : 초기의 인공 신경망. 다수의 입력으로 하나의 결과를 내보냄. 단층 퍼셉트론(SLP)과 다층 퍼셉트론(MLP)로 나뉨. 
  w^(t+1) = w+lr(y-y^(pred))x 의 학습(업데이트, 편향은 x=1)알고리즘을 가지고 있음.

- 입력층 : 데이터벡터화 
- 은닉층 : 수많은 뉴런 조합, 가중치에 따라 미분계산
- 출력층 : 결과로의 판단

- 학습 진행시 오차의 합이 최소화 하는 방향으로 모델 생성 > 이때 가장 일반적으로 경사하강법이 사용됨. 
- 경사 하강법 : 접선의 기울기가 최소가 되는 지점을 찾음. 이때 미분 사용. Learn Rate 를 적절한 값으로 설정하지 않으면 Local minima 에 빠지거나 연산이 너무 늦어질 수 있음. 
- 이터레이션 : 한번의 에포크를 끝내기 위해 필요한 배치 수.

- 손실함수 : 실제값과 예측값의 차이 수치화. 출력값이 기대값보다 얼마나 벗어나는지 측정.   
- 옵티마이저 : 손실함수로 산출된 점수에 의해 기중치 값을 조금씩 수정히는 과정을 담당. 이 괴정을 역전파라고 함. 

- 순전파(Forward Propagation) : 입력층에서 출력층 방향으로 연산하는 신경망. 예측값과 실제값의 오차를 계산. FFNN(Feed-Forward Neural Network).
- 역전파(Back Propagation) : 출력층에서 입력층 방향으로 연산. 옵티마이저의 수정(가중치 업데이트)과정. 출력층과 N층 사이의 가중치 업데이트(1단계)와 
  N층과 N-1층 사이의 가중치 업데이트(2단계)로 나뉨. 미분의 연쇄법칙(chain rule)사용.  

- 기울기 소실(gradient vanishing) : 역전파 과정에서 입력층으로 갈 수록 기울기가 0에 가까워져 가중치가 한없이 작아지는 문제.
- 기울기 폭주(gradient exploding) : 반대로 기울기가 커져 가중치가 커지는 바람에 결국 발산되어 한곳으로 모여들지를 못하는 문제. RNN에서 발생.
- Gradient Clipping : 기울기 폭주를 막기 위해 임계값을 넘지 않도록 임계치만큼 크기를 감소시킴. RNN 에서 유용. 
  keras 에서 optimizer.옵티마이저(clipnorm) 매개변수를 이용햐 수행할 수 있음. 
  
- Skewed(찌그러진)gradient : w1방향으로는 길고, w2방향으로는 짧은 구조. 각 가중치가 손실에 미치는 영향이 다를때 발생. 지그재그현상이 일어날 수 밖에 없음.
- 지그재그 현상 : 가중치 업데이트 중 (dL/dw)를 체인룰로 풀 때, sigmoid/ReLU를 사용하는 경우 w업데이트 행렬의 부호가 동일, 원하는 방향으로 가지 못해 지그재그로 목표점을 찾아가는 현상.   
- 플래튜(Plateau)현상 : 파라미터 학습 과정에서 평지가 생겨 조금씩 튀다 더이상 loss가 업데이트 되지 않는 현상. 

- 과적합 방지 : 데이터의 양을 늘리거나, 모델의 복잡도(은닉층, 매개변수 수. 수용력)를 줄이거나, 가중치 규제를 적용하거나, 드롭아웃을 적용하는 방법이 있다.
- 데이터 증강(data augmentation) : 데이터가 적을 경우, 과적합을 막기 위해 데이터를 조금씩 변형하고, 추가하는 방식으로 부풀려 성능을 좋게 만듦. (ex - 이미지:반전/자름/밝기조절 등)
- 가중치 감쇠(Weight decay) : 과적합을 막기 위해 함수의 복잡도를 조정할 수 있게 하는 기법. 인공신경망에서 L2규제의 다른 표현.
- 가중치규제(Regularization) : 과적합을 막기위해 복잡한 모델을 간단하게 하는 방법. L1, L2규제가 포함됨. 
- L1규제(L1노름) : 가중치들의 절댓값 합계를 비용함수에 추가. 모든 가중치의 λ|w|합계를 비용함수에 추가. 손실과 가중치의 합이 동시에 작아지도록 함. λ는 규제의 강도를 정하는 하이퍼 파라미터. 
- L2규제(L2노름) : 가중치들의 제곱합을 비용함수에 추가. 가중치가 0이 될 수 있음. 모든 가중치의 (1/2)λ(w^2)합계를 비용함수에 추가. 가중치 감쇠라고도 함. λ가 크면 규제의 강도가 강함.
- Dropout : 과적합 방지를 막기 위해 모델학습과정에서 값의 일부를 누락시킴. 네트워크 연산경로에 노이즈를 넣는 역할. 
  [자세히](https://ko.d2l.ai/chapter_deep-learning-basics/dropout.html)
  
- 가중치 초기화 : 기울기 소실과 폭주를 막음. 가중치가 어떤 초기값을 가졌느냐에 따라 모델의 훈련 결과가 달라지기도 하기에 시행. 
- 세이비어 초기화 : 균등분포(±√(6/(이전뉴런개수+다음뉴런개수))이내)/정규분포(평균0, 표준편차√(2/(이전뉴런개수+다음뉴런개수))로)이용으로 나뉨. 
  이전층과 다음층의 뉴런 개수를 이용해 초기화 범위와 조건을 지정. sigmoid/tanh 함수의 초기화방법.
- He 초기화 : 균등분포(±√(6/이전뉴런개수)이내)/정규분포(평균0, 표준편차√(2/이전뉴런개수)이내)이용으로 나뉨. 세이비어와 비슷하나 다음 뉴런 개수를 이용하지 않음. ReLU 계열 함수의 초기화방법.
  
- 배치 정규화 : 기울기 소실과 폭주를 막고, 가중치 초기화에 영향을 덜 받게하는 방법. 신경망의 각 층에 들어가는 입력을 배치단위로, 평균과 분산으로 정규화. 활성화 함수를 통과하기 전에 시행.
  [입력의 평균을 0으로 만듦 > 정규화 > 스케일/시프트]의 과정을 거침. 학습시 배치단위의 평균/분산을 받아 이동평균/이동분산을 저장, 이 후 테스트시 구해놓은 평균과 분산으로 정규화를 시행. 
- 배치 정규화 한계 : 미니 배치 크기에 의존적(작으면 잘 동작 X)이고, RNN에 적용하기 어렵(시점마다 다른 통계치를 가짐)다는 단점이 있음.
- 층 정규화 : 각 특성별로 정규화를 하는 배치 정규화와 비슷하나 각 층별로 정규화(평균과 표준편차를 구함). 배치정규화의 두 단점을 모두 개선.

- 내부 공변량 변화 : 학습 과정에서 층별로 입력 데이터 분포가 달라지는 현상. 훈련데이터와 테스트데이터의 분포가 다른경우, 신경망 층간의 입력데이터 분포 변화 모두를 이야기함. 

#### 활성화 함수(activation function)
***
- 활성화 함수 : 입력을 받아 수학적 변환을 수행해 출력을 생성하는 함수.
- 활성화 함수 특징 : 비선형 함수여야함(선형의 경우 은닉층을 연속으로 추가한것과 1회 추가한것의 차이가 없음).
- 선형층(투사층) : 선형함수를 사용한 층. 선형함수를 사용한 층 또한 학습가능한 파라미터가 생긴다는 의미는 가지기에 사용, 은닉층(활성화 함수 사용 층)과 구분하기 위해 사용.

- ReLU(Rectified Linear Unit) : ((X > 0)? X : 0)  |  가장 인기, 특정 양수값에 수렴하지 않아 깊은 신경망에서 좋고, 어떤 연산이 필요하지 않아 속도도 빠르나 
  입력값이 음수면 죽은 렐루(기울기 0)가 된다는 문제가 있음. 따라서 일반적으로는  SELU > ELU > LeakyReLU(그리고 변종들) > ReLU > tanh > sigmoid(다중 분류)순으로 사용함.
- Leaky ReLU : 죽은 렐루의 보완을 위한 변형 함수. 'Leaky'는 '새는'. 입력이 음수일 경우 아주 작은 값(0.01)을 반환. | max(ax, x). a는 하이퍼 파라미터(아주 작은 값). 빠름.
- RReLU(Randomized leaky ReLU) : a를 무작위로 선택하고 테스트시에는 평균을 사용하는 리키 렐루. 훈련세트의 과대적합의 위험을 줄이는 규제의 역할을 함.
- PReLU(Parametric leaky ReLU) : a가 훈련하는 동안 학습되는(일반 파라미터인) 리키렐루. 대규모 데이터셋에선 렐루보다 고성능을 보이나, 소규모에선 과대적합의 위험이 있음.
- ELU(Exponential Linear Unit) : x가 음수면 특정한 수(α, 보통 1)로 수렴하여 기울기 소실 문제와 deadReLU를 해결함. 타 변종보다 고성능. | ((X >= 0)? X : α(exp(x)-1))
- SELU(Scaled ELU) : 타 활성화 함수보다 뛰어난 성능을 보이나 입력이 반드시 표준화(평 0, 표준편차 1)되야하고, 모든 은닉층의 가중치가 르쿤(lecun_normal)으로 초기화 되야 하고, 
  일렬로 쌓은 층으로 구성되어야 자기정규화 됨. 훈련중 각 층의 출력이 평균0, 표준편차 1을 유지하는 경향이 있어, 기울기소실/폭주를 막아줌. | ((X >= 0)? X : α(e^x - 1))
- GELU(Gaussian Error Linear Unit) : 조금 더 유연한 ReLU. 깊으면 잘작동. 빠른 수렴과 음수에도 아주 적은 기울기를 반환할 수 있음. | 0.5x(1 + tanh(√(2/π)*(x + 0.044715(x^3))))  
- Swish : ReLU의 대체를 위해 구글이 고안한 함수. 매우 깊은 신경망에서/모든 배치크기에서 렐루를 능가함. CNN아키텍쳐중 모바일 넷의 학습에 사용됨. |  f(x) = x * 1/1+e^-x
- Sigmoid : 입력을 전부 0~1의 미분가능한 수로 변환. 이진 분류의 출력층에서 주로 사용. |  1/(1+np.exp(-x)) | 원점중심이 아니라 평균이 0.5이며, 
  항상 양수를 출력해 출력 가중치합 > 입력의 가중치합 이 될 가능성(편향이동)이 높아, 분산이 계속 커져 결국 기울기소실 문제가 생길 수 있음.
  시그모이드에서 기울기가 0에 가까운 양 극은 출력또한 0에 가까운 값이 나오게 되는데, 역전파 과정에서 이를 곱하면 기울기 소실 문제(앞쪽엔 기울기 잘 전달X, 학습X)가 발생.    
- tanh(Hyperbolic Tangent) : 입력을 -1~1의 미분 가능한 수로 변환. 시그모이드의 대체제. 
  시그모이드와 함께 Vanishing gradient problem(기울기 소실 문제)을 가지고 있으나 조금 더 나은 편. | (2/1+e^-2x) - 1
- softmax : 입력을 전부 0~1사이로 정규화. 출력의 총합이 1. 다중 분류의 출력층에서 주로 사용. |  np.exp(x) / np.sum(np.exp(x))
- hierarchical softmax(계층적) : 완전이진트리, root에서 단어 w까지 가는 길에 놓여있는 노드에 딸려 있는 벡터와, 단어leaf w_i와 연관된 벡터인 v_{wi}를 내적하고, 
  sigmoid를 적용해 확률로 만들고, 그 확률들을 곱하면서 leaf까지 내려감. 전체 합이 1이됨. [자세히](https://dalpo0814.tistory.com/7)

#### 활성화 도구(Optimizer)
***
![이미지](img/img.png)
- 손실함수에서 나온 손실을 이용해 가중치와 편향을 조정하는 알고리즘(도구). 최적화 알고리즘 이라고도 함. 
  로컬옵티마/플래튜/지그재그(찌그러진gradient)등 다양한 문제의 방지/해결을 위해 신경써야 함.
- 개선된(GD가 아닌)Optimizer에는 크게 모멘텀 방식, 어댑티브 방식으로 나뉨.
- 모멘텀 : 속도를 중시. 현재의 기울기+이전의 기울기를 포함해 누적된 가속도로 업데이트(관성). 찌그러진gradient제외 모든(뭉뚝,로컬,플래튜)문제 해결. 
  글로벌 옵티마도 추월하는 문제점 존재(Momen). Momentum, nag등이 존재. Momentum+RMSProp인 Adam도 존재함.
- 어댑티브 : 방향을 일직선으로 하는것을 중시. 각 가중치의 업데이트량을 보정(비슷하게)함. 지그재그 현상 해결. 
  실행할수록 느려지다(이전에 뛴 누적치로 나눠지는게 중첩)가중치가 0이된다는 문제점 존재(Ada). AdaGrad, RMSProp등이 존재.
  
- GD(Gradient descent) : 경사 하강법. 경사를 따라 내려가면서 가중치 업데이트. 비용함수를 미분해 함수의 기울기를 구한 후 비용이 최소화되는 방향을 찾아냄. 
- BGD(Batch Gradient Desent) : 배치 경사 하강법. 가장 기본적 경사 하강법. 오차를 구할 때 전체 데이터를 고려함. 
  한 학습당 시간이 오래 걸리고 메모리를 크게 요구하나 글로벌 미니멈을 찾을 수 있음.
- SGD(Stochastic gradient decent) : 확률적 경사 하강법. 매개변수 중 랜덤으로 선택한 하나의 데이터에 대해 계산. 변경 폭이 불안정하고, 정확도가 더 낮을 수 있으나 속도가 빠름.
- MBGD(Mini-Batch Gradient Descent) : 미니 배치 경사 하강법. 정해진 양에 대해서만 계산해 매개변수의 값을 조정. 미니배치 손실 계산 > 경사하강법 > 반복. 
  배치크기는 2의 제곱수를 사용하며, CPU/GPU메모리가 2배수이기 때문에 데이터 송수신의 효율을 높일 수 있기 때문임.
- Momentum : SGD + Momentum(이전 batch 학습결과 반영, 보통 이전:현재 = 9:1 정도). 관성을 응용. 로컬 미니멈을 글로벌 미니멈으로 인식해 계산이 끝났을 상황에서도 탈출하는 효과를 얻게 됨.
- AdaGrad : SGD + notation. 각 매개변수에 서로 다른 학습률 적용. 큰 변동 가중치 = 학습률 감소, 저변동 가중치 = 학습률 증가. 무한히 학습시 학습이 아예 안될 수 있음.
- RMSProp : AdaGrad 보완. 가중치보다 기울기가 크게 반영되도록 하고, 하이퍼 파라미터 p를 추가해 h가 무한히 커지지 않게 함. 
- Adam : RMSProp + Momentum. 방향과 학습률 두가지를 모두 잡기 위함. 각각 v와 h가 0으로 초기화 되면 학습 초반 W가 0으로 biased 되었는데, 이를 해결.
- NAG(Nesterov Accelerated Gradient, Nesterov Momentum) : Momentum을 진행한 상태에서 기울기를 계산해 더함. 모멘텀방식의 추월현상이 줄어듦.
  (현 기울기 + 이전 기울기 - 이전 기울기 누적치)의 변형공식이 있음. Momentum에 비해 성능이 크게 향상되진 않음.
- NAdam : Adam+NAG. NAG를 조금 변형한 후 Adam과 합침.

- Second Order optimization : first-order optimization(SGD)와 그 변형으로 이뤄진 위의 것들과는 다른 방식의 optimization. 
  단순한 이것의 사용을 위해서 Hessian Matrix란 2차행렬을 계산한 후 역행렬을 구해야 하는데, 이 과정의 계산량이 상대적으로 많아 특정 분야를 제외하곤 잘 쓰이지 않음.
  Newton's Method(뉴턴방식)를 기반으로 BFGS/L-BFGS(Hessian Matrix를 근사/추정하며 계산), Hessian-Free Optimization(헤시안 행렬을 직접 계산 x)등의 변형이 있음.
- L-BFGS : Limited BFGS. 준 뉴턴 방식(quasi-Newton methods)의 알고리즘 중 가장 흔히 쓰이는 방법. 많은 변수를 가진 최적화 문제에 적합. 
  제한된 메모리 내 에서 f(x)(스칼라 함수, 비선형 미분가능)를 제한 조건이 없는 실수 벡터 x에 대해서 최소화 시키는 것.

#### 손실함수(loss)
***
- 텐서 계산 > y값 산출 > 손실함수에 이용 > 손실 산출    의 구조로 이어짐.
- MSE(평균제곱오차) : 개별 예의 모든 제곱 손실을 합한 뒤 예의 수로 나눔. 선형 회귀 모델.
- binary_crossentropy : 이진 분류의 손실 함수. 
- categorical_crossentropy : 다중 분류 모델의 손실 함수. one-hot-encoding 된 결과로 입력을 해 주어야 하며, 3개의 클래스 별로 확률값이 나오게 된다. 
- sparse_categorical_crossentropy : 다중 분류 모델의 손실 함수. one-hot-encoding 을 할 필요 없이 정수형태(클래스 번호)로 결과값을 입력해주면 된다. 
  이런게 아닌 일반 모델에서 평범한 정수 인코딩(1,2,3 식)은 레이블 간 유사도를 전달하기에 회귀로 출 수 있는 분류 문제가 아닌 한 문제가 발생한다.

#### 하이퍼 파라미터(Hyper Parameter)
***
- 개발자(모델러)가 직접 설정하는, 모델의 학습에 영향을 미치는 수치.
- Learning rate         : 학습률. 옵티마이저를 이용한 가중치/편향 갱신시 어느크기로 수치를 변동할 지 설정.
- Dropout rate          : 과적합 방지를 위해 연산 과정에서 일부 값을 누락시킬 비율을 설정.
- Gradient cliping      : 기울기 폭주를 막기 위해 임계값을 넘지 않도록 감소시킬 크기를 설정. 주로 RNN등에서 사용.
- Momentum              : 이전 batch의 학습 결과를 반영할 정도를 설정.
- Weight initialization : 가중치의 초기값을 설정. 주로 랜덤값을 이용.
- Weight decay          : 가중치 감쇄를 위해 얼마나 감쇄(조정)할지 설정.
- data augmentation     : 데이터를 증강시켜 모델의 성능을 더 좋게 하기위해 얼마나/어떻게 증강시킬지 설정.
- Layer size            : 층의 크기(모델의 깊이). 모델을 얼마나 깊게/크게 만들 것 인지 설정.
- Batch size            : 전체 데이터를 어느 크기(batch)로 나눌지 설정.

#### ANN 성능 튜닝
- 미니 배치 : 모든 경우의 수를 계산하는(Full batch) 방법이 아닌 작은 양의 데이터를 분절해 최적값을 찾아나가는 방식.
- 가중치 규제 : 과적합 방지. L1(가중치들의 절댓값 합계를 비용 함수에 추가)과 L2(모든 가중치들의 제곱의 합계를 비용함수에 추가)가 있음.
- 드롭아웃 추가 : 과적합 방지. 훈련 중 무작위로 층의 일부 출력특성을 제외시킴. 신경망 모델에 융통성을 부여. 학습시에만 사용하고, 
  예측시엔 사용하지 않는 게 일반적. 서로 다른 신경망들을 앙상블해 사용하는 것 같은 효과를 냄.
- 네트워크 축소 : 모델의 학습 파라미터(가중치,편향)수를 줄임. 또 층을 추가하거나 제거해 다른 구조를 시도.
- 하이퍼 파라미터 튜닝 : 하이퍼 파라미터(층의 유닛수, 옵티마이저 학습률, 배치 등)를 바꿔 훈련을 함.

#### 신경망 용어
***
- ANN(Artificial Neural Networks) : 인공신경망. 딥러닝의 기초가 되고 있음. 파라미터의 최적값을 찾기 어렵다는 것과 
  Overfitting(과대적합, 훈련데이터보다 새 데이터에서 성능이 낮아짐) 문제가 있음.
- DNN(Deep Neural Networks) : 은닉층을 2개이상 지닌 학습 방법. 여기서 딥러닝이란 말이 파생. 기본적으로 H(X) = Wx * X + b 의 식을 이용하는데, 
  이때 가중치는 (입력의 열, 출력의 열)의 크기를 갖고, 편향과 출력의 크기는 같다.
- CNN(Convolutional Neural Networks, 합성곱신경망) : 데이터의 특징을 추출하여 특징들의 패턴을 파악. Convolution filter 를 사용하여 인식률을 높임. 
  MaxPooling(해당 conv-행렬- 안의 숫자중 가장 큰 숫자만 남김). 딥러닝에서 이미지, 영상데이터등의 처리, 정보 추출, 문장분류, 얼굴인식 등에 사용.  
- RNN(Recurrent Neural Networks, 순환신경망) : 반복적이고 순차적인 데이터 학습에 특화. 내부의 순환구조가 있음. 
  시계열 데이터에 과거의 학습 구조를 저장해 현재 학습에 이용해 예측률을 높임. LSTM 과 GRU 가 있음. 음성, 텍스트 성분파악등 에 이용.
- GAN(Generative Adversarial Network,생성적 적대 신경망) : 비지도 학습, 제로섬 게임 틀 안에서 서로 경쟁하는 두개의 신경 네트워크 시스템에 의해 구현. 
  fake 신경암을 추가해 서로 경쟁하여 더 좋은 성능을 내개 함. 

#### CNN
- CNN(Convolution Neural Network) : 합성곱 신경망. 이미지 처리에 탁월한 성능을 보임. 크게 합성곱층(합성곱연산 수행)과 풀링층 으로 구성. 
  이미지의 공간적인 구조 정보를 보존하며 학습. 다층 퍼셉트론보다 훨씬 적은 가중치를 사용(커널크기)하고, 편향은 커널 적용 뒤에 더해짐(커널적용 결과의 모든 원소에 추가).
- 합성곱 연산(CONV) : 이미지의 특징 추출. 커널(필터)라는 일정한 크기의 행렬로 이미지 전체를 훑으며(사용자 지정(stride)칸씩 이동, 좌>우,상>하)
  커널의 값(가중치)과 겹친 데이터를 각각 곱해 모두 더하여 해당 스텝의 출력으로 함. 다차원 텐서에 합성곱 연산을 적용하려면 커널이 입력과 같은 채널(차원)수를 가져야 하며, 
  각 채널의 결과를 모두 더해 하나의 채널을 가지는 특성맵을 만듦.
  결과인 특성맵은 int((입력높이-커널높이)/스트라이드 + 1)의 높이와 int((입력너비-커널너비)/스트라이드 + 1)의 너비를 가짐.
- 패딩 : 합성곱 연산 이후에도 본래 크기와 같은 이미지(행렬)를 얻기 위해 연산전 가장자리에 행과 열을 늘림. 보통 0을 삽입해(제로패딩)패딩.
- 풀링 : 특성맵을 다운샘플링해 특성맵의 크기를 줄임. 특성맵의 가중치 개수를 줄여줌. 일반적으로 최대(max)풀링/평균(average)풀링 두가지중 하나가 사용되며, 합성곱층 이후 추가됨.
  
- 1D CNN : 자연어처리에 사용되는 CNN. 벡터화된 문장을 입력으로 받아, 입력과 커널의 너비를 동일하게 한 뒤 높이를 조절해(y축으로만 이동)합성곱 연산을 수행.

#### GAN
- DCGAN(Deep Convolution) : Convolution 필터만 사용하고 Max Pooling 은 사용하지 않음. 안정성 분제를 조금이나마 해결할 수 있다.
- LSGAN(Least Squares) : 결정 상자에서 멀리 떨어진 데이터는 페널티를 줌.
- SGAN(Semi-Supervised) : 데이터를 구분할 때 fake 클래스도 구분한다. 총 10개의 클래스가 있다면 fake 까지 총 11개의 클래스가 생긴다.
- ACGAN(Auxiliary Classifier) : SGAN 에 Generator 가 학습을 진행할수록 좋은 이미지를 만들어내고 어느 순간부터 데이터가 
  augmentation 기능을 할 수 있다는 특징이 있다. 먼저 R/F 를 구분한 뒤 어떤 클래스인지 구분한다는 특징이 있다. 
- cGAN : 기존 noise Z 만 가지고 무작위로 이미지를 생성했던 GAN 과 달리 특정 레이블 y 가 추가되며 특정 이미지만 고정적으로 생산가능하다. 
- 실제 현실의 이미지는 너무 많은 변수가 있다는 문제점이 있었고, 이로 인해 이 개념을 이용해 복잡한 이미지나 영상까지 변경 가능하게 한 pix2pix 가 탄생했다.
- pix2pix : 데이터 형태와 무관하게 범용적으로 사용 가능, 다른 종류의 손실함수(L1, L2, 유클라디안 > GAN 기반 Loss 학습) 사용 이라는 특징을 가지고 있다.
###### GAN code (clone)
```python 
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("./mnist/data/", one_hot=True)
print(mnist.train.images, mnist.train.labels)

# parameter
total_epochs = 100
batch_size = 100
learning_rate = 0.0002
n_hidden = 256
n_input = 28 * 28
n_noise = 128 

X = tf.placeholder(tf.float32, [None, n_input])
Z = tf.placeholder(tf.float32, [None, n_noise])

# make generator
G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))
G_b1 = tf.Variable(tf.zeros([n_hidden]))
G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))
G_b2 = tf.Variable(tf.zeros([n_input]))

def generator(noise_z):
   hidden = tf.nn.relu(
                   tf.matmul(noise_z, G_W1) + G_b1)
   output = tf.nn.sigmoid(
                   tf.matmul(hidden, G_W2) + G_b2)

   return output

# make discriminator
D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))
D_b1 = tf.Variable(tf.zeros([n_hidden]))
D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))
D_b2 = tf.Variable(tf.zeros([1]))

def discriminator(inputs):
   hidden = tf.nn.relu(
                   tf.matmul(inputs, D_W1) + D_b1)
   output = tf.nn.sigmoid(
                   tf.matmul(hidden, D_W2) + D_b2)

   return output

# make random noise
def get_noise(batch_size, n_noise):
   return np.random.normal(size=(batch_size, n_noise))

G = generator(Z)  # make random image with noise
D_gene = discriminator(G)  # get number of classification image's reality 
D_real = discriminator(X)  # with real image

loss_D = -tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))
loss_G = -tf.reduce_mean(tf.log(D_gene)

D_var_list = [D_W1, D_b1, D_W2, D_b2]
G_var_list = [G_W1, G_b1, G_W2, G_b2]

train_D = tf.train.AdamOptimizer(learning_rate).minimize(loss_D, var_list=D_var_list)
train_G = tf.train.AdamOptimizer(learning_rate).minimize(loss_G, var_list=G_var_list)


sess = tf.Session()  # Launch session.
sess.run(tf.global_variables_initializer())  # clear variable 

total_batch = int(mnist.train.num_examples/batch_size) 
loss_val_D, loss_val_G = 0, 0  # set default loss

for epoch in range(total_epoch):
    for i in range(total_batch):
        batch_xs, batch_ys = mnist.train.next_batch(batch_size)
        noise = get_noise(batch_size, n_noise)

        # train each NN (Generator and Discriminator)
        _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X: batch_xs, Z: noise})
        _, loss_val_G = sess.run([train_G, loss_G], feed_dict={Z: noise})

    print('Epoch:', '%04d' % epoch,
          'D loss: {:.4}'.format(loss_val_D),
          'G loss: {:.4}'.format(loss_val_G))

    if epoch % 10 == 0:
        sample_size = 10
        noise = get_noise(sample_size, n_noise)
        samples = sess.run(G, feed_dict={Z: noise})

        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))

        for i in range(sample_size):
            ax[i].set_axis_off()
            ax[i].imshow(np.reshape(samples[i], (28, 28)))

        plt.savefig('./result/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')
        plt.close(fig)

print('최적화 완료')
```

### 비지도학습
출력 없이 오직 입력만 입력된 데이터를 그룹화,분석. 스케일 조정등도 비지도.
레이블이 없기에 뭔가 유용한 것을 학습했는지 평가해야 하며, 그 결과를 확인하기 위해서는 직접 확인하는 것이 유일한 방법일 때가 많다는 과제가 있음.

#### 비지도 변환
- 비지도 변환 : 데이터를 새롭게 표현해 사람이나 다른 머신러닝 알고리즘이 원래 데이터보다 쉽게 해석할 수 있도록 하는 알고리즘. 
  차원축소(특성이 많은 고차원 데이터 셋을 특성의 수를 줄이며 꼭 필요한 특징을 포함한 데이터로 표현 )분야에서 널리 사용. 데이터를 구성하는 단위나 성분을 찾기도 함.
#### 군집 (clustering)
- 클러스터링 : 데이터를 비슷한 것끼리 그룹으로 묶음. 
- 자동 군집 탐지. 데이터 마이닝 기법의 일환. 목표 변수 없이 패턴을 찾아냄. 비지도 기법이지만. 비즈니스의 목적에 띠라(마케팅,CRM,고객segmentation)지도활동이 추기되는 경우기 있음.
- 하드 클러스터링 : 각 레코드를 하나의 클러스터에 연관시킴. 대부분 이걸로 사용.
- 소프트 클러스터링 : 각 레코드를 여러개의 클러스터에 연결시킴.  
- K 평균 클러스터링 알고리즘 : 임의로 K개의 레코드 선택, 각 레코드를 가장 가까운 시드에 배정(군집간 경계 찾음), 군집들의 중심점을 찾음, 군집 생성 완료

### 오토인코더(AutoEncoder)
- 오토인코더 : 입력을 출력으로 복사하는 신경망. 항상 인코더와 디코더로 되어있고, 입력과 출력의 뉴런수가 동일함. 여러 제약을 주어 바로 복사하지 못하게 방지하며, 데이터의 효율적 표현 방법을 학습함.
- Undercomplete AutoEncoder : 히든레이어의 노드수가 입력층보다 작은 오토인코더. 입력이 저차원으로 표현되어, 오토인코더가 입력데이터에서 가장 중요한 특성을 학습하도록 만듦. 
- Denoising AutoEncoder : 입력에 노이즈를 추가하고, 노이즈가 없는 원본 입력을 제구성하도록 하는 오토 인코더. 입력층 바로 뒤에 가우시안 노이즈를 추가하거나 드롭아웃을 적용함. 중요한 특성을 학습.
- Sparse AutoEncoder : 희소성을 이용하는 오토인코더. 좋은 특성을 추출하도록 만듦. 손실함수에 적절한 항을 추가해 정가운데에서 활성화되는 뉴런수를 감소시킴(전체의 5%만 활성화되게 하면 그걸로 입력을 재구성).
- Variational AutoEncoder(VAE) : 확률적/생성 오토인코더. 학습후에도 출력이 부분적 우연에 의해 결정되며, 샘플링된것과 같은 새 샘플을 생성할 수 있음. 
- Stacked/Deep AutoEncoder : 여러개의 히든레이어를 가지는 오토인코더. 레이어를 추가할수록 더 복잡한 정보를 학습할 수 있음. 인코더와 디코더가 대칭구조를 가짐.

### 강화학습(Reinforcement Learning)
***
- 비지도학습에 속합. 주어진 환경에서 에이전트의 행동을 통해 결과로 보상을 받아 모델을 학습해 나가는 과정.
- multi armed bandit : 여러개의 슬롯머신중 가장 많은 보상을 주는 기계를 찾아가는 강화학습 모델. 
  중간 중간 기계의 보상 설정 값이 변화하는 상황이 발생하며, 강화학습의 이해에 가장 좋은 방법.

## GCP
- GCP : 구글 클라우드 플랫폼. 관리형 JupyterNoteBook인 AI PlatformNotebook, Kubeflow Pipelines인 AI Platform Pipeline, AI Platform이 속해있어, AI의 학습, 실험, 배포가 가능함.
- 사용방법(주피터) : 먼저 프로젝트를 생성한 뒤 API(ComputeEngineAPI)를 활성화시킴 -> 인스턴스 생성(타입은 변경,추가가 가능) -> OpenJupyterLab 에서 AI PlatformNotebook 사용가능. 
- 시용방법(파이프라인) : AI Platform > Pipelines에서 인스턴스 생성(노트북과 동일한 프로젝트) -> 클러스터 생성 ->  설치 후 설정, 배포(컴포넌츠 설치)로 Kubeflow Pipelines 사용가능.
- 사용방법(Cloud Stroage) : AI Platform Pipelines 설치시 생성된 버킷(Storage > Browser에서 확인가능)에 필요 폴더를 생성한 뒤 데이터를 업로드, 모델을 생성/학습함으로 사용가능.

# Questions
## numpy
1. numpy는 왜 인기가 많을까요? : 대용량 데이터 배열을 효율적으로(빠름, 메모리 적게)사용. 
   - 내부 데이터를 다른 파이썬객체와 구분된 연속된 메모리블록에 저장, 내부 알고리즘이 전부 C로 작성되 타입검사/오버헤드 없이 메모리 직접 조작가능.
   - 내장 파이썬 연속자료형보다 훨씬 적은 메모리 사용, 반복문 없이 전체 배열에 대한 복잡한 계산 실행. 다양한 데이터형을 자유롭게 사용가능, 과학기술수치계산 지원.
    
2. numpy와 GPU의 관계는 어떻게 되나요? : gpu는 넘파이를 지원하지 않음.
   - numpy 머신러닝 코드가 GPU버전으로 업그레이드 될 수 없음(지원하지 않음).
   - pytorch, tensorflow는 numpy와 호환되는 자료형을 지원하면서 동시에 GPU도 지원하니, GPU사용시엔 그걸 사용하면 된다.

3. reshape 가능한 조건이 어떻게 될까요? : 전체 요소의 개수가 일정해야 함.
   - (5,4)의 배열의 경우 (10,2)나 (2,5,2)로 나뉠 수 있음.
   - (-1, 2)처럼 지정하면, 행은 남은 요소에 맞게, 열은 2로 설정하겠다는 뜻임.  
   
4. dtype 변경시에 어떤 일들이 일어날까요? : 내부 자료가 해당 자료형에 맞게 변화하는 등 다양한 변화가 있음.
   - 내부 자료가 변화(실수>정수 시 소수점이 전부 짤린다던가), 필요 bit수 변화. 부동소수점 데이터 형으로 변환시 오버플로우를 막아주는 효과도 있음.
   - numpy의 자료형은 Boolean, Integer, Unsigned Integer, Float, Complex, Sting이 있음.
   - python 기본 자료형에 비해 사용가능한 함수와 속성이 훨씬 많음. 

5. numpy에서 deep copy는 뭔가요? : 전혀 다른 메모리 공간에 값만 같은 배열을 복사하는 것.
   - numpy 에는 세가지 복사가 있는데, 평범한 대입, ViewCopy, DeepCopy 임.
   - 평범한 대입 : 대입한 변수의 값을 바꾸면 본래 배열에도 영향이 가는, 그저 이름만 다른 변수를 하나 생성하는 것(메모리 공간 공유).
   - View Copy : ndarray.view() 로 복사 시. 복사한 배열의 크기등을 바꾸는건 본래의 배열과 상관이 없지만, 데이터를 바꾸면 원래 배열의 데이터값도 바뀜.
   - Deep Copy : ndarray.copy() 로 복사 시. 최상단의 설명과 동읾함.
   
6. numpy 같은 syntax는 어떻게 구현할 수 있나요? : C의 (2차원)배열/List, (다중)반복문등을 써서 만들 수 있음.
   - numpy(Numerical(수치)Python)는 C에서 구현된 파이썬 라이브러리. 고성능의 수치계산을 위해 제작.
   - array라는 단위로 데이터를 관리, 이에 대해 연산. 따라서 데이터 타입을 가진 행렬을 통해 데이터를 관리하고, 그에 대해 연산하면 구현 가능하지 않을까 함.
   
7. numpy 데이터를 보관하는 방법은 어떤게 있을까요? : np.save(), .savez(), .savez_compressed(), .saveText() 등의 함수를 사용해 가능.
   - .save() : 배열 한개를 numpy 포맷의 binary파일로 저장(.npy)
   - .savez() : 여러개의 배열을 1개의 압축되지 않은 (.npz) 포맷 파일로 저장.
   - .savez_compressed() : 여러개의 배열을 1개의 압축된 (.npz) 포맷 파일로 저장.
   - .savetext() : 여러개의 배열을 텍스트 파일로 저장(.txt)

## boostcamp 
### 통계학, 수학
- 고유값/고유벡터란? 중요한 이유는? : 
- 샘플링/리샘플링이란? 리샘플링의 장점은? : 샘플링-아날로그신호를 디지털신호로 바꾸는 것.
- 확률모형/확률변수란? : 
- 누적분포함수/확률밀도함수란? : 
- 조건부확률이란? : 어떤 사건A가 일어났을때(일어났다는 조건하에)다른 사건 B가 일어날 확률(P(B|A)).
- 공분산/상관계수란? (수식과 함께) : 
- 신뢰구간의 정의는? :
- p-value란? :
- R square란? : 
- 평균,중앙값이 각각 이용되는 케이스는? : 
- 중심극한정리란? 유용한 이유는? : 
- 엔트로피(entropy)/InforamtionGain은 무엇인가? :
- 모수적 방법론, 비모수적 방법론이 쓰이는 경우는? : 
- "likelihood"와 "probability"의 차이는? : 
- 통계에서의 bootstrap이란? : 
- 모수가 매우적은 케이스에서 예측모델을 수립하는 방법은? : 
- 베이지안/프리퀀티스트 간의 입장차이는? : 
- 검정력(statistical power)이란? : 
- missing value가 있다면 채워야 하나? 그 아유는? : 
- 아웃라이어의 판단기준은? : 
- 필요한 표본의 크기 계산 방법은? : 
- 편향을 통제하는 방법은? : 
- 로그함수가 유용한 경우는? : 
- 베르누이/이항/카테고리/다항/가우시안정규/t/카이제곱/F/베타/감마 분포란? 분포간의 연관성은? : 
- 같은 지역에 사는 세 친구가 각 2/3으로 진실을, 1/3로 거짓을 말할때, 모두 비가 내리고있다고 했다면 실제로 비가 내릴 확률은? :
### 머신러닝
- 알고있는 metrics에 대해 설명?(ex-RMSE,MAE,recall,precision) :
  accuracy : 정확도. 전체 데이터중 맞힌 비율. (TP+TN)/(TP+FP+TN+FN). 
  precision : 정밀도. P로 예측한 것 중 진짜 P인 비율. FP을 줄여야 할 때(P의 예측이 정확해야 할 때)사용. TP/(TP+FP).
  recall : 재현율. 전체 P중 예측한 P의 비율. FN를 줄여야 할 때(모든 P를 맞혀야 할 때)사용. TP/(TP+FN). 
  F-1 measure(score) : 정밀도와 재현율의 조화평균(곱/합). 데이터의 편향이 심할때 사용.
  RMES : 평균제곱근오차. √(MSE). 회귀모델에서 사용.
  MAE : 평균절댓값오차. 손실의 절댓값의 평균. 회귀모델에서 사용.

- 정규화를 하는 이유와 방법은? : 각 입력의 범위와 크기가 다를경우 학습이 어려워 사용.
  정규분포 : (데이터-평균)/표준편차 로 정규화. 평균이 0, 표준편차가 1인 0~1의 값이 됨.
  균등분포 : 모든 데이터를 같은 확률(비율)로 정규화. 0~1의 값이 됨.킴.
  일반화 : 각 특성벡터의 유클리디안 거리가 1이 되도록 조정. 길이는 상관 없이 데이터의 각도(방향)이 중요할 때 사용.
  
- Local minima/Global minima 란? : 
  Local : 에러를 최소화해 최적의 파라미터를 찾는 과정에서 나타나는 지역적인 홀(에러가 잠깐 다시 늘어났다 다시 줄어드는 구간).
  Global : 전역적인 해. 전 학습 과정에서 에러가 최소인 구간.
  극복방법 : 실제 딥러닝에서는 로컬 minima에 빠질 확률이 거의 없음(모든 파라미터가 로컬 옵티마(미니마)에 빠져야 하기 때문).

- 차원의 저주란? : 학습을 위해 차원이 증가함에 따라 모델의 성능이 저하되는 현상. 개별차원 내 학습데이터가 줄어들어 발생. 차원을 줄이거나 데이터를 많이 해 해결가능.
- 차원축소기법의 종류는? : 
  피처 선택(Feature Selection) : 특정 피터에 종속성이 강한 불필요피처를 아예 제거하고, 데이터의 특징을 잘 나타내는 주요 피처만 선택하는 방법.
  피처 추출(Feature extraction) : 기존 피처(특성)를 저차원의 중요 피처로 압축해 추출하는 방법. 기존 피처와는 완전히 다른 값이 됨. 
  PCA(Principal Component Analysis) : 주성분 분석. 여러 변수간 상관관계를 이용(가장높은 분산(한 변수간 변동)을 가지는 데이터의 축을 찾음), 주성분을 추출해 차원을 축소. 스케일 변환이 중요.
  LDA(Linear Discriminant Analysis) : 선형 판별 분석. PCA에서 확장된 차원축소기법. 지도학습에서 적용하는 차원 축소 기법이자, 입력데이터의 클래스를 최대한 분리할 수 있는 축을 찾는 기법.
  SVD(Singular Value Decomposion) : 특이값 분해. 정사각 행렬이 아닌 m*n형태의 다양한 행렬을 분해하며, 이때 두개의 직교행렬(특이벡터)과 하나의 대각 행렬로 분해됨.
  LSA(Latent Sematic Analysis) : 잠재 의미 분석. 단어-문서행렬등 입력데이터에 SVD를 수행해 차원수를 줄여, 계산효율성을 키움과 동시에 숨어있는 의미를 이끌어내는 방법.
  NMF(Non-negative Matrix Factorization) : 비음수 행렬분해. 전체 원소가 양수인 행렬V를 음수를 포함하지 않는 행렬 W(특성에 대한 적합도\*특성)와 H(특성\*특성에 대한 중요도)의 곱으로 분해하는 알고리즘. 대략적인 해를 구함.
  
- PCA가 차원축소기법/데이터압축기법/노이즈제거기법 인 이유는? : 
  차원축소 : PCA의 기본적 개념은 차원이 큰 벡터에서 선형독립(직교)하는 고유 벡터(주성분)만을 남겨두고 차원을 축소하는 것. 각 차원의 분산을 최대로 갖는, 분포를 설명할 수 있는 대표축을 뽑음.
  데이터압축 : 차원축소과정에서 상관성이 높은 독립변수들을 N개의 선형 조합으로 만들며 변수의 개수를 요약, 압축함. 압축된 각 독립변수들은 선형독립(직교)하며 낮은 상관성을 보임.
  노이즈제거 : 높은 주성분들만 선택하며 정보설명력이 낮은(노이즈로 구성된)칼럼은 배제함.

- LSA,LDA,SVD의 뜻은? 서로간의 관계는? : 전부 차원축소기법임.
  LSA : 잠재 의미 분석. 단어-문서행렬등 입력데이터에 SVD를 수행해 차원수를 줄여, 계산효율성을 키움과 동시에 숨어있는 의미를 이끌어내는 방법.
  LDA : 선형판별 분석. PCA의 변형으로, 지도학습에서 클래스를 최대한 나누는 축을 찾는 차원축소기법.
  SVD : 특이값 분해. 특정 행렬을 두개의 직교행렬과 하나의 대각 행렬(U, Σ, V^T)로 나누는 차원축소기법.
  
- Markov Chain이란? : (?)
- 텍스트더미에서 주제를 추출할 때, 당신이 선택할 접근방식은? : 
- SVM이 차원을 확장시키는 방식으로 동작하는 이유는? 좋은 이유는? : 
- 나이브베이즈 기법의 장점은? : 
- 회귀/분류에 각각 알맞은 metric은? : 
- Association Rule의 Support, Confidence, Lift란? : 
- 최적화 기법중 Newton's Method와 GradientDesent는 무엇인가? : 
- 머신러닝적 접근방법과 통계적 접근방법의 차이에 관한 견해는? : 
- 인공신경망(딥러닝 이전, 정통적인)의 문제점은? : 
- 지금 나오고있는 딥러닝 계열 혁신의 근간은? : 발전한 하드웨어, 모으기 쉬워진 데이터셋, 증가한 인공지능에 대한 관심 | 트랜스포머, 퓨샷러닝등
- ROC커브란? : 
- 서버 100대를 가지고 있다고 할 때, 인공신경망보다 랜덤포레스트를 써야 하는 이유는? : 
- K평균 알고리즘의 대표적 의미론적 단점은(계산량 제외)? : 
- L1, L2 정규화란? : 
- CrossValidation이란? : 
- XGBoost란? 이 모델이 유명한 이유는? : 
- 앙상블 방법의 종류는? : 
- featuer vector란? : 
- 좋은모델이란? : 
- 50개의 작은 의사결정트리는 큰 의사결정트리보다 좋은가? 그 이유는? : 
- 스팸필터에 로지스틱 회귀를 많이 사용하는 이유는? : 
- OLS(ordinary least squer) regression의 공식은? : 
### 딥러닝
- 딥러닝이란? 딥러닝과 머신러닝의 차이는? : 
- Cost funtion, Activation function이란? : 
- Tensorflow, Pytorch의 특징과 차이점은? : 
- Data Normaliztion이란? 필요한 이유는? : 
- Activation function의 종류는? : 
- 과적합에 대처하는 방법은? : 
- 하이퍼 파라미터란? : 
- 가중치 초기화 방법은? 주로 사용하는 것은? : 
- 볼츠만머신이란? :
- tf,PyTorch 사용시 디버깅 노하우는? :
- NN의 가장 큰 단점은? OneShotLearning은? :
- sigmoid보다 ReLU가 사용되는 이유는(비선형의 의미와 필요성, ReLU가 곡선함수를 근사하는 방법/문제점, 편향의 존재이유)? : 
- GradientDescent란(사용이유, 가로/세로축의 의미, 때때로 Loss증가이유, 역전파를 쉽게 설명하면)? : 
- Local minima를 딥러닝이 피하는 방법은? 찾은해가 GlobalMinimum인지 알아보는 방법은? : 
- Training/Test세트를 나누는 이유는(검증세트의 존재이유, Test세트 오염의 뜻, 정규화란)? : 
- Batch Normalization/Dropout의 호과는? BN적용학습시 주의점/GAN_Generator에서 BN사용가능? : 
- 옵티마이저(SGD, RMSprop, Adam)에 대해 아는대로 설명한다면? : 
- 간단한 Mnist룰 MLP+CPU, numpy로 만든다면 줄수는? 작성까지의 시간은? 역전파과정의 줄수는? CNN으로 바꾼다면? : 
- 간단한 Mnist를 TF,PyTorch로 바꾼다면 작성 시간은? CNN아닌 MLP사용 여부, 마지막 레이어, 학습은 BCE, 확인은 MSE를 원한다면 메세지가 갈겁니다.
- 딥러닝 시 GPU를 쓰면 좋은 이유는? :
### 파이썬
- 리스트와 튜플의 차이점은? : 
- 키의 특징은? : 
- 파이썬은 어떤 언어인가? 프로그래밍/스크립팅(scripting)? : 
- 파이썬은 인터프리터 언어이다. 설명한다면? : 
- pep8 이란? : 
- 파이썬에선 어떻게 메모리가 다뤄(managed)지는가? : 
- 파이썬에서 네임스페이스란? : 
- PYTHONPATH란? : 
- 파이썬 모듈이란? built-in 모듈에서 흔하게 사용되는 이름은? : 
- 파이썬에서 지역변수/전역변수란? : 
- 파이썬의 케이스는 예민한가? : 
- 파이썬에서 형변환은 무엇인가? : 
- 윈도우에서 파이썬을 설치하고 path변수를 설정하는 방법은? : 
- 파이썬에서 들여쓰기(indentation)가 요구되는가? : 
- Python Arrays와 List의 차이는? : 
- 파이썬에서 functions 는 무엇인가? : 
- __init__은 무엇인가? : 
- lambda 함수란 무엇인가? : 
- 파이썬에서 self란? : 
- break, continue, pass가 어떻게 동작(work)하는가? : 
- [::-1\]은 무엇(어떻게 작동)을 하는가? : 
- list의 항목을 랜덤으로 하는 방법은? : 
- iterator와 iterable의 차이점은? : 
- 파이썬에서 난수생성방법은? : 
- range와 xrange의 차이점은? : 
- 파이썬에서 주석을 다는 방법은? : 
- pickling/unpickling은 무엇인가? : 
- 파이썬에서 generators란? : 
- 문자열의 첫글자를 대문자화 하는 방법은? : 
- 문자열을 소문자화하는 방법은? : 
- 여러줄에 주석을 다는 방법은? : 
- docstring이란? : 
- 연산자에서 is, not의 목적은? : 
- help(), dir() 함수의 사용법은? : 
- 파이썬이 종료될때 마다 모든 메모리가 할당취소되지 않는 이유는? : 
- 삼항연산자(ternary operators)는 어떻게 사용될 수 있는가? : 
- *args/**kwargs 의 의미는? 이것을 사용하는 이유는? : 
- len()이 하는 것은? : 
- "re"모듈의 split(), sub(), subn()은 무엇인가? : 
- 음수인 인덱스는 무엇이며 왜 사용되는가? : 
- Python packages란? : 
- 파이썬에서 파일은 어떻게 삭제될 수 있는가? : 
- built-in 타입이란 무엇인가? : 
- 넘파이 배열이 파이썬 lists보다 뛰어나게 제공하는 장점은? :
- 파이썬 array에 값을 추가/제거하는 방법은? : 
- 파이썬은 OOps conceots(개념)을 가지고 있는가? : 
- deep copy와 shallow copy의 차이는? : 
- 파이썬에서 멀티쓰레딩이 달성되는 방법은? : 
- 파이썬의 편집(compliation)과 연결(linking)프로세스는 무엇인가? : 
- 파이썬의 라이브러리는 무엇인가?(몇 개의 이름과 같이) : 
- split이 쓰이는 이유는? : 
- 파이썬에서 모듈 import방법은? : 
- 파이썬의 상속을 설명한다면?(예와 함께) : 
- 파이썬에서 클래스 생성 방법은? : 
- monkey patching이란? : 
- 파이썬은 다중상속을 지원하는가? : 
- 파이썬의 다형성(Polymorphism)이란? : 
- 파이썬엔 캡술화(encapsulation)가 정의되어있는가? : 
- 파이썬에서 데이터추상화(data abstraction)를 하는 방법은? : 
- 파이썬은 접근지정자를 생성하는가? : 
- 파이썬에서 빈 클래스를 만드는 방법은? : 
- object()가 하는 것은? : 
- 파이썬에서 map함수란? : 
- 넘파이가 list보다 더 좋은가? : 
- 파이썬 언어의 GIL이란 무엇인가? : 
- CPython과 Python의 차이점은? : 
- 데코레이터란? : 
- object interning이란? : 
- @classmethod, @staticmethod, @property 란? : 
### 자료구조
- 연결리스트 > 단일연결리스트, 이중연결리스트, 원형연결리스트 : 
- 해쉬 테이블(hash table) : 
- 스택 : 
- 큐 > 큐, 원형큐 : 
- 그래프 : 
- 트리 > 이진트리, 포화이진트리, 완전이진트리, 이진탐색트리 : 
- 힙 > 최소 힙, 최대 힙 : 
- red-black 트리 : 
- b+ 트리 : 
### 알고리즘
- 시간/공간 복잡도 : 
- 정렬알고리즘 > 버블/선택/삽입/병합/힙/퀵/Counting/Radix정렬 : 
- Divide and Conquer : 
- 다이나믹 프로그래밍 : 
- Greedy 알고리즘 : 
- 그래프 > Graph Traversal(BFS, DFS), 최단거리(Dijkstra, Floyd-Warshall, Bellman-Fold), 
   Minimum Spanning Tree(Prim, Kruskal), Union-find, Topological(위상)sort : 
### 네트워크
- TCP/IP 각 계층 설명, OSI 7계층과 차이 설명 : 
- Frame, Packet, Segment, Datagram을 비교 : 
- TCP와 UDP의 차이, 헤더를 비교 설명 : 
- TCP의 3-way-handshake와 4-way-handshake를 비교셜명 : 
- TCP의 연결설정과정(3단계)와 연결종료과정(4단계)가 차이나는 이유 :
- 서버에서 FIN플래그 전송전 전송한 패킷이 FIN패킷보다 늦게 도착하게 된다면? :  
- 초기 Sequence Number인 ISN을 0부터 시작하는게 아닌 난수를 생성해 설정하는 이유는? : 
- HTTP, HTTPS와 둘의 차이점에 대해 설명, 동작과정을 비교 : 
- HTTP 요청/응답 헤더의 구조 설명 : 
- HTTP GET과 POST 메서드 비교 설명 : 
- 쿠키(Cookie)와 세션(Session)설명 : 
- CORS란? : 
- DNS란? : 
- REST, RESTful과 차이를 설명 : 
- 소켓(Socket)이란? (자신있는 언어로 소켓생성 예시) : 
- Socket.io와 WebSocket의 차이 : 
- IPv4와 IPv6의 차이 : 
- MAC Address란? : 
- 라우터, 스위치, 허브의 차이 : 
- SMTP란? : 
- 노트북으로 www.google.com 접속시 요청을 보내고 받는 과정 자세히 설명 : 
- 여러 네트워크 topology에 대해 설명 : 
- subnet mask에 대해 설명 : 
- data encapsulation(캡슐화)란? :  
- DHCP란? : 
- routing protocol을 몇가지 설명(link state, distance vector 등) : 
- 이더넷(ethernet)이란? : 
- 클라이언트와 서버의 차이점 : 
- delay, timing(jitter), throughput의 차이 셜명 :
### OS
- 프로세스와 스레드의 차이점 : 
- 멀티프로세스 대신 멀티 스레드를 사용하는 이유 : 
- 캐시의 지역성에 대해 설명 : 
- Thread-safe에 대해 설명(critical section) : 
- 뮤텍스와 세마포어의 차이 : 
- 스케줄러, 단기/중기/장기로 나누는 기준에 대해 설명 : 
- CPU스케줄러(FCFS, SJF, SRTF, Priority Scheduling, RR)에 대해 설명 : 
- 동기와 비동기의 차이 : 
- 메모리 관리 전략의 종류 : 
- 가상메모리에 대해 설명 : 
- 교착상태(Deadlock)의 개념과 조건을 설명 : 
- 사용자 수준 스레드와 커널수준 스레드의 차이 : 
- 외부단편화와 내부단편화에 대해 설명 : 
- Context Switching에 대해 설명, 과정나열 : 
- Swapping에 대해 설명 : 

## DL_Question
- [source](https://m.facebook.com/story.php?story_fbid=1834909203473235&id=100008625183805)
- 1. 요즘 Sigmoid 보다 ReLU를 많이 쓰는데 그 이유는?
- + Non-Linearity라는 말의 의미와 그 필요성은?
- + ReLU로 어떻게 곡선 함수를 근사하나?
- + ReLU의 문제점은?
- + Bias는 왜 있는걸까?
- 2. Gradient Descent에 대해서 쉽게 설명한다면?
- + 왜 꼭 Gradient를 써야 할까?
- + 그 그래프에서 가로축과 세로축 각각은 무엇인가?
- + 실제 상황에서는 그 그래프가 어떻게 그려질까?
- + GD 중에 때때로 Loss가 증가하는 이유는?
- + 중학생이 이해할 수 있게 더 쉽게 설명 한다면?
- + Back Propagation에 대해서 쉽게 설명 한다면?
- 3. Local Minima 문제에도 불구하고 딥러닝이 잘 되는 이유는?
- + GD가 Local Minima 문제를 피하는 방법은?
- + 찾은 해가 Global Minimum인지 아닌지 알 수 있는 방법은?
- 4. CNN에 대해서 아는대로 얘기하라
- + CNN이 MLP보다 좋은 이유는?
- + 어떤 CNN의 파라메터 개수를 계산해 본다면?
- + 주어진 CNN과 똑같은 MLP를 만들 수 있나?
- + 풀링시에 만약 Max를 사용한다면 그 이유는?
- + 시퀀스 데이터에 CNN을 적용하는 것이 가능할까?
- 5. Word2Vec의 원리는?
- + 그 그림에서 왼쪽 파라메터들을 임베딩으로 쓰는 이유는?
- + 그 그림에서 오른쪽 파라메터들의 의미는 무엇일까?
- + 남자와 여자가 가까울까? 남자와 자동차가 가까울까?
- + 번역을 Unsupervised로 할 수 있을까?
- 6. Auto Encoder에 대해서 아는대로 얘기하라
- + MNIST AE를 TF나 Keras등으로 만든다면 몇줄일까?
- + MNIST에 대해서 임베딩 차원을 1로 해도 학습이 될까?
- + 임베딩 차원을 늘렸을 때의 장단점은?
- + AE 학습시 항상 Loss를 0으로 만들수 있을까?
- + VAE는 무엇인가?
- 7. Training 세트와 Test 세트를 분리하는 이유는?
- + Validation 세트가 따로 있는 이유는?
- + Test 세트가 오염되었다는 말의 뜻은?
- + Regularization이란 무엇인가?
- 8. Batch Normalization의 효과는?
- + Dropout의 효과는?
- + BN 적용해서 학습 이후 실제 사용시에 주의할 점은? 코드로는?
- + GAN에서 Generator 쪽에도 BN을 적용해도 될까?
- 9. SGD, RMSprop, Adam에 대해서 아는대로 설명한다면?
- + SGD에서 Stochastic의 의미는?
- + 미니배치를 작게 할때의 장단점은?
- + 모멘텀의 수식을 적어 본다면?
- 10. 간단한 MNIST 분류기를 MLP+CPU 버전으로 numpy로 만든다면 몇줄일까?
- + 어느 정도 돌아가는 녀석을 작성하기까지 몇시간 정도 걸릴까?
- + Back Propagation은 몇줄인가?
- + CNN으로 바꾼다면 얼마나 추가될까?
- 11. 간단한 MNIST 분류기를 TF나 Keras 등으로 작성하는데 몇시간이 필요한가?
- + CNN이 아닌 MLP로 해도 잘 될까?
- + 마지막 레이어 부분에 대해서 설명 한다면?
- + 학습은 BCE loss로 하되 상황을 MSE loss로 보고 싶다면?
- + 만약 한글 (인쇄물) OCR을 만든다면 데이터 수집은 어떻게 할 수 있을까?
- 12. 간단한 MNIST DCGAN을 작성한다면 TF 등으로 몇줄 정도 될까?
- + GAN의 Loss를 적어보면?
- + D를 학습할때 G의 Weight을 고정해야 한다. 방법은?
- + 학습이 잘 안될때 시도해 볼 수 있는 방법들은?
- 13. 딥러닝할 때 GPU를 쓰면 좋은 이유는?
- + 학습 중인데 GPU를 100% 사용하지 않고 있다. 이유는?
- + GPU를 두개 다 쓰고 싶다. 방법은?
- + 학습시 필요한 GPU 메모리는 어떻게 계산하는가?
- 14. TF 또는 Keras 등을 사용할 때 디버깅 노하우는?
- 15. Collaborative Filtering에 대해 설명한다면?
- 16. AutoML이 뭐하는 걸까?

# Computer
- 컴퓨터의 기본구조 : 트랜지스터 수천억개가 연결되어있음.
- 트랜지스터 : NPN, N이 각각 +와-에 연결되어있다, p에 전압을 주면 전류가 흐르게됨. 스위치와 달리 물리적 힘이 필요없다는 특징이 있음.
# license
### open source
- MIT/Apache : 코드는 마음대로 해도 되나(상업적 포함), 해당 코드의 제작자/제작기관을 고소하는것은 불가능.
- GPL : 코드를 가져다 앱을 만들어도 되나, 이를 공개하고 싶다면 앱/결과물/코드 전부 오픈소스(GPL라이센스)로 공개해야 함.
- 표준저작권법(Standard Copyright Law) : 코드에 대한 저작권을 가져 허락없이 재생산/배포/변형이 불가능함.
